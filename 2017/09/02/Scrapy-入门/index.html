<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.0 -->
    <script>
        window.materialVersion = "1.5.0"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">


    <link rel="dns-prefetch" href="https://cdn1.lncld.net"/>



    <link rel="dns-prefetch" href="https://changyan.sohu.com"/>











    <!-- Title -->
    
    <title>
        
            Scrapy 入门 | 
        
        changoal
    </title>

    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="format-detection" content="telephone=no"/>
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="chang">
    <meta name="description" itemprop="description" content="十年之前和现�?">
    <meta name="keywords" content="十年之前和现在,Python,爬虫">

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(key){try{localStorage.removeItem(key)}catch(e){}};lsloader.setLS=function(key,val){try{localStorage.setItem(key,val)}catch(e){}};lsloader.getLS=function(key){var val="";try{val=localStorage.getItem(key)}catch(e){val=""}return val};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var keys=[];for(var i=0;i<localStorage.length;i++){keys.push(localStorage.key(i))}keys.forEach(function(key){var data=lsloader.getLS(key);if(window.oldVersion){var remove=window.oldVersion.reduce(function(p,c){return p||data.indexOf("/*"+c+"*/")!==-1},false);if(remove){lsloader.removeLS(key)}}})}catch(e){}};lsloader.clean();lsloader.load=function(jsname,jspath,cssonload,isJs){if(typeof cssonload==="boolean"){isJs=cssonload;cssonload=undefined}isJs=isJs||false;cssonload=cssonload||function(){};var code;code=this.getLS(jsname);if(code&&code.indexOf(versionString)===-1){this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}if(code){var versionNumber=code.split(versionString)[0];if(versionNumber!=jspath){console.log("reload:"+jspath);this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}code=code.split(versionString)[1];if(isJs){this.jsRunSequence.push({name:jsname,code:code});this.runjs(jspath,jsname,code)}else{document.getElementById(jsname).appendChild(document.createTextNode(code));cssonload()}}else{this.requestResource(jsname,jspath,cssonload,isJs)}};lsloader.requestResource=function(name,path,cssonload,isJs){var that=this;if(isJs){this.iojs(path,name,function(path,name,code){that.setLS(name,path+versionString+code);that.runjs(path,name,code)})}else{this.iocss(path,name,function(code){document.getElementById(name).appendChild(document.createTextNode(code));that.setLS(name,path+versionString+code)},cssonload)}};lsloader.iojs=function(path,jsname,callback){var that=this;that.jsRunSequence.push({name:jsname,code:""});try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(path,jsname,xhr.response);return}}that.jsfallback(path,jsname)}};xhr.send(null)}catch(e){that.jsfallback(path,jsname)}};lsloader.iocss=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.iofonts=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.runjs=function(path,name,code){if(!!name&&!!code){for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code=code}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var script=document.createElement("script");script.appendChild(document.createTextNode(this.jsRunSequence[0].code));script.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(script);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var that=this;var script=document.createElement("script");script.src=this.jsRunSequence[0].path;script.type="text/javascript";this.jsRunSequence[0].status="loading";script.onload=function(){that.jsRunSequence.shift();if(that.jsRunSequence.length>0){that.runjs()}};document.body.appendChild(script)}};lsloader.tagLoad=function(path,name){this.jsRunSequence.push({name:name,code:"",path:path,status:"failed"});this.runjs()};lsloader.jsfallback=function(path,name){if(!!this.jsnamemap[name]){return}else{this.jsnamemap[name]=name}for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code="";this.jsRunSequence[k].status="failed";this.jsRunSequence[k].path=path}}this.runjs()};lsloader.cssfallback=function(path,name,cssonload){if(!!this.cssnamemap[name]){return}else{this.cssnamemap[name]=1}var link=document.createElement("link");link.type="text/css";link.href=path;link.rel="stylesheet";link.onload=link.onerror=cssonload;var root=document.getElementsByTagName("script")[0];root.parentNode.insertBefore(link,root)};lsloader.runInlineScript=function(scriptId,codeId){var code=document.getElementById(codeId).innerText;this.jsRunSequence.push({name:scriptId,code:code});this.runjs()};lsloader.loadCombo=function(jslist){var updateList="";var requestingModules={};for(var k in jslist){var LS=this.getLS(jslist[k].name);if(!!LS){var version=LS.split(versionString)[0];var code=LS.split(versionString)[1]}else{var version=""}if(version==jslist[k].path){this.jsRunSequence.push({name:jslist[k].name,code:code,path:jslist[k].path})}else{this.jsRunSequence.push({name:jslist[k].name,code:null,path:jslist[k].path,status:"comboloading"});requestingModules[jslist[k].name]=true;updateList+=(updateList==""?"":";")+jslist[k].path}}var that=this;if(!!updateList){var xhr=new XMLHttpRequest;xhr.open("get",combo+updateList,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){that.runCombo(xhr.response,requestingModules);return}}else{for(var i in that.jsRunSequence){if(requestingModules[that.jsRunSequence[i].name]){that.jsRunSequence[i].status="failed"}}that.runjs()}}};xhr.send(null)}this.runjs()};lsloader.runCombo=function(comboCode,requestingModules){comboCode=comboCode.split("/*combojs*/");comboCode.shift();for(var k in this.jsRunSequence){if(!!requestingModules[this.jsRunSequence[k].name]&&!!comboCode[0]){this.jsRunSequence[k].status="comboJS";this.jsRunSequence[k].code=comboCode[0];this.setLS(this.jsRunSequence[k].name,this.jsRunSequence[k].path+versionString+comboCode[0]);comboCode.shift()}}this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/avatar_round.png">
    <link rel="icon" sizes="192x192" href="/img/avatar_round.png">
    <link rel="apple-touch-icon" href="/img/avatar.jpg">

    <!--iOS -->
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="changoal">

    <!-- Site Verification -->
    
    

    <!-- RSS -->
    

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #e9ebec;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icon -->

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==", true)</script>
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://yoursite.com">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Scrapy 入门 | changoal">
    <meta property="og:image" content="http://yoursite.com/img/avatar_round.png" />
    <meta property="og:description" content="十年之前和现�?">
    <meta property="og:article:tag" content="Python"> <meta property="og:article:tag" content="爬虫"> 

    
        <meta property="article:published_time" content="Sat Sep 02 2017 21:19:00 GMT+0800" />
        <meta property="article:modified_time" content="Sat Sep 02 2017 21:20:10 GMT+0800" />
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:title" content="Scrapy 入门 | changoal">
    <meta name="twitter:description" content="十年之前和现�?">
    <meta name="twitter:image" content="http://yoursite.com/img/avatar_round.png">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:url" content="http://yoursite.com" />

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://yoursite.com/2017/09/02/Scrapy-入门/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://yoursite.com/2017/09/02/Scrapy-入门/index.html",
    "headline": "Scrapy 入门",
    "datePublished": "Sat Sep 02 2017 21:19:00 GMT+0800",
    "dateModified": "Sat Sep 02 2017 21:20:10 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "chang",
        "image": {
            "@type": "ImageObject",
            "url": "http://o797mwhn1.bkt.clouddn.com/avatar.jpg"
        },
        "description": "十年之前和现在"
    },
    "publisher": {
        "@type": "Organization",
        "name": "changoal",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/avatar_round.png"
        }
    },
    "keywords": ",Python,爬虫十年之前和现在",
    "description": "十年之前和现�?",
}
</script>


    

    <!-- Analytics -->
    
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-105599788-1', 'auto');ga('send', 'pageview');
</script>
    
    
    
        <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1263984656&web_id=1263984656" language="JavaScript"></script>
</div>
    

    <!-- Custom Head -->
    

</head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#scrapy-介绍"><span class="post-toc-number">1.</span> <span class="post-toc-text">scrapy 介绍</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#环境搭建"><span class="post-toc-number">2.</span> <span class="post-toc-text">环境搭建</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#开始"><span class="post-toc-number">3.</span> <span class="post-toc-text">开始</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#新建项目"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">新建项目</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#目录结构"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">目录结构</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#架构"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">架构</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#写代码"><span class="post-toc-number">3.4.</span> <span class="post-toc-text">写代码</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#定义字段"><span class="post-toc-number">3.4.1.</span> <span class="post-toc-text">定义字段</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#编写-spider"><span class="post-toc-number">3.4.2.</span> <span class="post-toc-text">编写 spider</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#自定义-Pipeline"><span class="post-toc-number">3.4.3.</span> <span class="post-toc-text">自定义 Pipeline</span></a></li></ol></li></ol></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        
            <!-- Random Thumbnail -->
            <div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
            <script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 19 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script>

        
    
            <p class="article-headline-p">
                Scrapy 入门
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="http://o797mwhn1.bkt.clouddn.com/avatar.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>chang</strong>
        <span>9月 02, 2017</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/Python/">Python</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/爬虫/">爬虫</a>
    </ul>
    

    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    
    <!-- Leancloud Views -->
        <a class="post_share-link" href="#">
            <li class="mdl-menu__item">
                <span id="/2017/09/02/Scrapy-入门/" class="leancloud-views_num" data-flag-title="Scrapy 入门">
     &nbsp;浏览量
</span>

            </li>
        </a>
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=Scrapy 入门&url=http://yoursite.com/2017/09/02/Scrapy-入门/index.html&pic=http://yoursite.com/img/avatar_round.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=Scrapy 入门&url=http://yoursite.com/2017/09/02/Scrapy-入门/index.html&via=chang" target="_blank">
            <li class="mdl-menu__item">
                分享到 Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2017/09/02/Scrapy-入门/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    
        <a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=changoal&title=Scrapy 入门&summary=十年之前和现�?&pics=http://yoursite.com/img/avatar_round.png&url=http://yoursite.com/2017/09/02/Scrapy-入门/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 QQ
            </li>
        </a>
    

    <!-- Share Telegram -->
    
</ul>

</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <h1 id="scrapy-介绍"><a href="#scrapy-介绍" class="headerlink" title="scrapy 介绍"></a>scrapy 介绍</h1><p>scrapy 是一个基于 Python 语言的爬虫框架。有了框架的存在，我们可以更方便的爬虫了，框架帮我们封装好了下载等模块，而且更重要的是框架使用了异步的模式，加快了爬虫的速度。</p>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>在命令行中执行 <code>conda install Scrapy</code> 这样就安装好了 Scrapy 模块，是不是特别简单。ahahahha</p>
<h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>接下来就要开始我们的 scrapy 之路了。</p>
<h2 id="新建项目"><a href="#新建项目" class="headerlink" title="新建项目"></a>新建项目</h2><p>使用 Scrapy 第一步：创建项目，命令行进入你需要放置项目的目录，然后执行</p>
<p> <code>scrapy startproject ScrapyDemo   #ScrapyDemo是项目名称</code> </p>
<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>这时会在目录下多出一个 ScrapyDemo 文件夹，这就是 Scrapy 项目了，项目的结构如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">|-- ScrapyDemo</span><br><span class="line">|   `-- ScrapyDemo</span><br><span class="line">|       |-- spiders</span><br><span class="line">|       |   `-- __init__.py</span><br><span class="line">|       |-- __init__.py</span><br><span class="line">|       |-- items.py</span><br><span class="line">|       |-- middlewares.py</span><br><span class="line">|       |-- pipelines.py</span><br><span class="line">|       `-- settings.py</span><br><span class="line">`-- scrapy.cfg</span><br></pre></td></tr></table></figure></p>
<p>目录说明：</p>
<ul>
<li>ScrapyDemo(外层) 项目总目录</li>
<li>ScrapyDemo(内层) 项目目录</li>
<li>scrapy.cfg 项目的配置文件</li>
<li>spiders 放置我们的爬虫代码的目录</li>
<li>items.py 定义我们需要获取的字段</li>
<li>middlewares.py </li>
<li>pipelines.py 用来定义存储</li>
<li>settings.py 项目设置文件</li>
</ul>
<p>还有一点要注意的是，Scrapy 默认是不能在 IDE 中调试的，所以要在项目总目录下新建一个 entrypoint.py 文件，写下以下内容：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前两个参数是不变的，第三个参数是自己定义的 spider 的名字</span></span><br><span class="line">execute([<span class="string">'scrapy'</span>, <span class="string">'crawl'</span>, <span class="string">'dingdian'</span>])</span><br></pre></td></tr></table></figure></p>
<p>现在整个目录应该是这样（盗图..）</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/11/%E5%BF%AB%E6%8D%B7%E5%90%AF%E5%8A%A8.png" alt=""></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下面我们先来看一下框架的架构图</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/scrapy_architecture.png" alt=""></p>
<blockquote>
<p>Scrapy Engine: 这是引擎，负责Spiders、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等等！（像不像人的身体？）</p>
<p>Scheduler(调度器): 它负责接受引擎发送过来的requests请求，并按照一定的方式进行整理排列，入队、并等待Scrapy Engine(引擎)来请求时，交给引擎。</p>
<p>Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spiders来处理，</p>
<p>Spiders：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</p>
<p>Item Pipeline：它负责处理Spiders中获取到的Item，并进行处理，比如去重，持久化存储（存数据库，写入文件，总之就是保存数据用的）</p>
<p>Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件</p>
<p>Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spiders中间‘通信’的功能组件（比如进入Spiders的Responses;和从Spiders出去的Requests）</p>
</blockquote>
<p>数据在整个Scrapy的流向：</p>
<blockquote>
<p>程序运行的时候，</p>
<p>引擎：Hi！Spider, 你要处理哪一个网站？</p>
<p>Spiders：我要处理23wx.com</p>
<p>引擎：你把第一个需要的处理的URL给我吧。</p>
<p>Spiders：给你第一个URL是XXXXXXX.com</p>
<p>引擎：Hi！调度器，我这有request你帮我排序入队一下。</p>
<p>调度器：好的，正在处理你等一下。</p>
<p>引擎：Hi！调度器，把你处理好的request给我，</p>
<p>调度器：给你，这是我处理好的request</p>
<p>引擎：Hi！下载器，你按照下载中间件的设置帮我下载一下这个request</p>
<p>下载器：好的！给你，这是下载好的东西。（如果失败：不好意思，这个request下载失败，然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载。）</p>
<p>引擎：Hi！Spiders，这是下载好的东西，并且已经按照Spider中间件处理过了，你处理一下（注意！这儿responses默认是交给def parse这个函数处理的）</p>
<p>Spiders：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，这是我需要跟进的URL，将它的responses交给函数 def  xxxx(self, responses)处理。还有这是我获取到的Item。</p>
<p>引擎：Hi ！Item Pipeline 我这儿有个item你帮我处理一下！调度器！这是我需要的URL你帮我处理下。然后从第四步开始循环，直到获取到你需要的信息，</p>
<p>注意！只有当调度器中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的 URL，Scrapy会重新下载。）</p>
</blockquote>
<h2 id="写代码"><a href="#写代码" class="headerlink" title="写代码"></a>写代码</h2><p>建立一个项目之后：</p>
<p>第一件事就是在 items.py 文件中定义我们需要的字段，用来临时存储要保存的数据，方便以后数据的持久化存储，比如 数据库 文本文件等。</p>
<p>第二件事是在 spiders.py 中编写自己的爬虫代码</p>
<p>第三件事是在 pipelines.py 中存储自己的数据</p>
<p><strong>建议：在大家调试的时候在settings.py中取消下面几行的注释：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HTTPCACHE_ENABLED = <span class="keyword">True</span></span><br><span class="line">HTTPCACHE_EXPIRATION_SECS = <span class="number">0</span></span><br><span class="line">HTTPCACHE_DIR = <span class="string">'httpcache'</span></span><br><span class="line">HTTPCACHE_IGNORE_HTTP_CODES = []</span><br><span class="line">HTTPCACHE_STORAGE = <span class="string">'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br></pre></td></tr></table></figure></p>
<p>上面代码的作用是 Scrapy 会缓存你有的 Requests！ 当你再次请求时，如果存在缓存文档则返回缓存文档，而不是去网站请求，这样既加快了本地调试速度，也减轻了 网站的压力。一举多得</p>
<h3 id="定义字段"><a href="#定义字段" class="headerlink" title="定义字段"></a>定义字段</h3><p>要根据自己要爬取的内容来定义字段。比如，在这里我们要爬的是小说站点就需要定义，小说名字，作者，小说地址，连载状态，字数，文章类别 等字段。</p>
<p>就像下面这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrapydemoItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># 小说名字</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    <span class="comment"># 作者</span></span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    <span class="comment"># 小说地址</span></span><br><span class="line">    novelurl = scrapy.Field()</span><br><span class="line">    <span class="comment"># 连载状态</span></span><br><span class="line">    serialstatus = scrapy.Field()</span><br><span class="line">    <span class="comment"># 连载字数</span></span><br><span class="line">    serialnumber = scrapy.Field()</span><br><span class="line">    <span class="comment"># 类别</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line">    <span class="comment"># 编号</span></span><br><span class="line">    novel_id = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<h3 id="编写-spider"><a href="#编写-spider" class="headerlink" title="编写 spider"></a>编写 spider</h3><p>在 spiders 目录下新建一个 ScrapyDemo.py 文件，并导入我们需用的模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy </span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> ScrapyDemo.items <span class="keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Muspider</span><span class="params">(scrapy.Spider)</span>:</span></span><br></pre></td></tr></table></figure>
<p>我们需要从一个地址入手开始爬取，我在顶点小说上没有发现有全站小说地址，但是我找到每个分类地址全部小说：</p>
<p>玄幻魔幻：<a href="http://www.x23us.com/class/1_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/1_1.html</a></p>
<p>武侠修真：<a href="http://www.x23us.com/class/2_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/2_1.html</a></p>
<p>都市言情：<a href="http://www.x23us.com/class/3_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/3_1.html</a></p>
<p>历史军事：<a href="http://www.x23us.com/class/4_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/4_1.html</a></p>
<p>侦探推理：<a href="http://www.x23us.com/class/5_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/5_1.html</a></p>
<p>网游动漫：<a href="http://www.x23us.com/class/6_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/6_1.html</a></p>
<p>科幻小说：<a href="http://www.x23us.com/class/7_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/7_1.html</a></p>
<p>恐怖灵异：<a href="http://www.x23us.com/class/8_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/8_1.html</a></p>
<p>散文诗词：<a href="http://www.x23us.com/class/9_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/9_1.html</a></p>
<p>其他：<a href="http://www.x23us.com/class/10_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/10_1.html</a></p>
<p>全本：<a href="http://www.x23us.com/quanben/1" target="_blank" rel="noopener">http://www.x23us.com/quanben/1</a></p>
<p>好啦！入口地址我们找到了，现在开始写第一部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> ScrapyDemo.items <span class="keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Myspider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ScrapyDemo'</span></span><br><span class="line">    allowed_domains = [<span class="string">'x23us.com'</span>]</span><br><span class="line">    bash_url = <span class="string">'http://www.x23us.com/class/'</span></span><br><span class="line">    bashurl = <span class="string">'.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">            url = self.bash_url + str(i) + <span class="string">'_1'</span> + self.bashurl</span><br><span class="line">            <span class="keyword">yield</span> Request(url,self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        print(response.text)</span><br></pre></td></tr></table></figure>
<p>首先我们创建一个类 Myspider；这个类继承自 scrapy.Spider</p>
<p>定义了一个 allowed_domains ；这个不是必须的；但是在某写情况下需要用得到，比如使用爬取规则的时候就需要了；它的作用是只会跟进存在于 allowed_domains 中的 URL。不存在的 URL 会被忽略。</p>
<p><strong>第九行定义的 name 是之前我们在 entrypoint.py 文件中的第三个参数 此 name 在整个项目中有且只能有一个、名字不可重复！！！</strong></p>
<p>之后可以运行 entrypoint.py 文件来检查一下代码时候可以正常工作。</p>
<p>请求就这么轻而易举的实现了啊！简直So Easy！</p>
<p>继续 继续！</p>
<p>我们需要历遍所有页面才能取得所有的小说页面连接：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/11/%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B52.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> ScrapyDemo.items <span class="keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Muspider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'ScrapyDemo'</span></span><br><span class="line">    allowed_domains = [<span class="string">'x23us.com'</span>]</span><br><span class="line">    bash_url = <span class="string">'http://www.x23us.com/class/'</span></span><br><span class="line">    bashurl = <span class="string">'.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">            url = self.bash_url + str(i) + <span class="string">'_1'</span> + self.bashurl</span><br><span class="line">            <span class="keyword">yield</span> Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        max_span = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'div'</span>, class_=<span class="string">'pagelink'</span>).find_all(<span class="string">'a'</span>)[<span class="number">-1</span>].get_text()</span><br><span class="line">        bashurl = str(response.url)[:<span class="number">-6</span>]</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>, int(max_span) + <span class="number">1</span>):</span><br><span class="line">            url = bashurl + str(num) + self.bashurl</span><br><span class="line">            <span class="keyword">yield</span> Request(url, self.get_name)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        novels = BeautifulSoup(str(response), <span class="string">'lxml'</span>).find_all(<span class="string">'tr'</span>, bgcolor=<span class="string">'#F2F2F2'</span>)</span><br><span class="line">        <span class="keyword">for</span> navel <span class="keyword">in</span> novels:</span><br><span class="line">            a = navel.find(<span class="string">'a'</span>)</span><br><span class="line">            name = a[<span class="string">'title'</span>]</span><br><span class="line">            url = a[<span class="string">'href'</span>]</span><br><span class="line">            <span class="keyword">yield</span> Request(url, callback=self.get_chapterurl, meta=&#123;<span class="string">'name'</span>: name, <span class="string">'url'</span>: url&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_chapterurl</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = ScrapydemoItem()</span><br><span class="line">        item[<span class="string">'name'</span>] = str(response.meta[<span class="string">'name'</span>]).replace(<span class="string">'\xa0'</span>, <span class="string">''</span>)</span><br><span class="line">        item[<span class="string">'novelurl'</span>] = response.meta[<span class="string">'url'</span>]</span><br><span class="line">        category = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'table'</span>).find(<span class="string">'a'</span>).get_text()</span><br><span class="line">        author = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'table'</span>).find_all(<span class="string">'td'</span>)[<span class="number">1</span>].get_text()</span><br><span class="line">        bash_url = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'p'</span>, class_=<span class="string">'btnlinks'</span>).find(<span class="string">'a'</span>, class_=<span class="string">'read'</span>)[<span class="string">'href'</span>]</span><br><span class="line">        name_id = str(bash_url)[<span class="number">-6</span>:<span class="number">-1</span>].replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">        item[<span class="string">'category'</span>] = str(category).replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">        item[<span class="string">'author'</span>] = str(author).replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">        item[<span class="string">'name_id'</span>] = name_id</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h3 id="自定义-Pipeline"><a href="#自定义-Pipeline" class="headerlink" title="自定义 Pipeline"></a>自定义 Pipeline</h3><p>做一个自定义的MySQL的Pipeline。首先为了能好区分框架自带的Pipeline，我们把MySQL的Pipeline单独放到一个目录里面。</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy12.png" alt=""></p>
<p>pipelines.py  这个是我们写存放数据的文件</p>
<p>sql.py 看名字就知道，需要的sql语句。</p>
<p>首先是需要的 MySQL 表,<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`dd_name`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`dd_name`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`xs_name`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`xs_author`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`category`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`name_id`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">38</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4;</span><br></pre></td></tr></table></figure></p>
<p>记得在 settings.py 文件中定义好 MySQL 的配置文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MYSQL_HOSTS = <span class="string">'127.0.0.1'</span></span><br><span class="line">MYSQL_USER = <span class="string">'root'</span></span><br><span class="line">MYSQL_PORT = <span class="string">'3306'</span></span><br><span class="line">MYSQL_PASSWORD = <span class="string">'****'</span></span><br><span class="line">MYSQL_DB = <span class="string">'xiaoshuo'</span></span><br></pre></td></tr></table></figure></p>
<p>在开始写sql.py之前，我们需要安装一个Python操作MySQL的包，来自MySQL官方的一个包：<a href="http://cdn.mysql.com//Downloads/Connector-Python/mysql-connector-python-2.1.4.zip" target="_blank" rel="noopener">点我下载</a></p>
<p>下载完成后解压出来，从 cmd 进入该目录的绝对路径，然后 python setup.py install ；即可完成安装(记得以管理员身份打开命令行)</p>
<p>sql.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mysql.connector</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ScrapyDemo <span class="keyword">import</span> settings</span><br><span class="line"></span><br><span class="line">MYSQL_USER = settings.MYSQL_USER</span><br><span class="line">MYSQL_PASSWORD = settings.MYSQL_PASSWORD</span><br><span class="line">MYSQL_HOST = settings.MYSQL_HOSTS</span><br><span class="line">MYSQL_PORT = settings.MYSQL_PORT</span><br><span class="line">MYSQL_DB = settings.MYSQL_DB</span><br><span class="line"></span><br><span class="line">cnx = mysql.connector.connect(user=MYSQL_USER, password=MYSQL_PASSWORD, host=MYSQL_HOST, database=MYSQL_DB)</span><br><span class="line">cur = cnx.cursor(buffered=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sql</span>:</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert_dd_name</span><span class="params">(cls, xs_name, xs_author, category, name_id)</span>:</span></span><br><span class="line">        sql = <span class="string">'INSERT INTO dd_name (`xs_name`,`xs_author`,`category`,``name_id) VALUES (%(xs_name)s,%(xs_author)s,,%(category)s,,%(name_id)s)'</span></span><br><span class="line">        VALUE = &#123;</span><br><span class="line">            <span class="string">'xs_name'</span>: xs_name,</span><br><span class="line">            <span class="string">'xs_author'</span>: xs_author,</span><br><span class="line">            <span class="string">'category'</span>: category,</span><br><span class="line">            <span class="string">'name_id'</span>: name_id</span><br><span class="line">        &#125;</span><br><span class="line">        cur.execute(sql, VALUE)</span><br><span class="line">        cnx.commit()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select_name</span><span class="params">(cls, name_id)</span>:</span></span><br><span class="line">        sql = <span class="string">'SELECT EXISTS(SELECT 1 FROM dd_name WHERE name_id=%(name_id)s)'</span></span><br><span class="line">        value = &#123;</span><br><span class="line">            <span class="string">'name_id'</span>: name_id</span><br><span class="line">        &#125;</span><br><span class="line">        cur.execute(sql, value)</span><br><span class="line">        cnx.commit()</span><br></pre></td></tr></table></figure></p>
<p>来开始写pipeline<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ScrapyDemo.items <span class="keyword">import</span> ScrapydemoItem</span><br><span class="line"><span class="keyword">from</span> .sql <span class="keyword">import</span> Sql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrapyPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, sqider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(item, ScrapydemoItem):</span><br><span class="line">            name_id = item[<span class="string">'name_id'</span>]</span><br><span class="line">            ret = Sql.select_name(name_id)</span><br><span class="line">            <span class="keyword">if</span> ret[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">                print(<span class="string">'已经存在了'</span>)</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                xs_name = item[<span class="string">'xs_name'</span>]</span><br><span class="line">                xs_author = item[<span class="string">'xs_author'</span>]</span><br><span class="line">                category = item[<span class="string">'category'</span>]</span><br><span class="line">                Sql.insert_dd_name(xs_name, xs_author, category, name_id)</span><br><span class="line">                print(<span class="string">'开始存小说标题'</span>)</span><br></pre></td></tr></table></figure></p>
<p>定义了一个process_item函数并有，item和spider这两个参数（<strong>请注意啊！这两玩意儿 务必！！！要加上！！千万不能少！！！！务必！！！务必！！！</strong>）</p>
<p>搞完！下面我们启用这个Pipeline在settings中作如下设置：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/setting02.png" alt=""></p>
<p>后面的 1 是优先级程度（1-1000随意设置，数值越低，组件的优先级越高）</p>
<p>下面我们开始还剩下的一些内容获取：小说章节 和章节内容</p>
<p>首先我们在 item.py 中新定义一些需要获取内容的字段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScrapydemoItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># 小说名字</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    <span class="comment"># 作者</span></span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    <span class="comment"># 小说地址</span></span><br><span class="line">    novelurl = scrapy.Field()</span><br><span class="line">    <span class="comment"># 连载状态</span></span><br><span class="line">    serialstatus = scrapy.Field()</span><br><span class="line">    <span class="comment"># 连载字数</span></span><br><span class="line">    serialnumber = scrapy.Field()</span><br><span class="line">    <span class="comment"># 类别</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line">    <span class="comment"># 编号</span></span><br><span class="line">    novel_id = scrapy.Field()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Content</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    id_name = scrapy.Field()</span><br><span class="line">    chaptercontent = scrapy.Field()</span><br><span class="line">    num = scrapy.Field()</span><br><span class="line">    chapter_url = scrapy.Field()</span><br><span class="line">    chapter_name = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>继续编写Spider文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chapterurl</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    item = ScrapydemoItem()</span><br><span class="line">    item[<span class="string">'name'</span>] = str(response.meta[<span class="string">'name'</span>]).replace(<span class="string">'\xa0'</span>, <span class="string">''</span>)</span><br><span class="line">    item[<span class="string">'novelurl'</span>] = response.meta[<span class="string">'url'</span>]</span><br><span class="line">    category = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'table'</span>).find(<span class="string">'a'</span>).get_text()</span><br><span class="line">    author = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'table'</span>).find_all(<span class="string">'td'</span>)[<span class="number">1</span>].get_text()</span><br><span class="line">    bash_url = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'p'</span>, class_=<span class="string">'btnlinks'</span>).find(<span class="string">'a'</span>, class_=<span class="string">'read'</span>)[<span class="string">'href'</span>]</span><br><span class="line">    name_id = str(bash_url)[<span class="number">-6</span>:<span class="number">-1</span>].replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">    item[<span class="string">'category'</span>] = str(category).replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">    item[<span class="string">'author'</span>] = str(author).replace(<span class="string">'/'</span>, <span class="string">''</span>)</span><br><span class="line">    item[<span class="string">'name_id'</span>] = name_id</span><br><span class="line">    <span class="keyword">yield</span> item</span><br><span class="line">    <span class="keyword">yield</span> Request(bash_url, callback=self.get_chapter, meta=&#123;<span class="string">'name_id'</span>: name_id&#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chapter</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    urls = re.findall(<span class="string">r'&lt;td class="L"&gt;&lt;a href="(.*?)"&gt;(.*?)&lt;/a&gt;&lt;/td&gt;'</span>, response.text)</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        num = num + <span class="number">1</span></span><br><span class="line">        chapterurl = response.url + url[<span class="number">0</span>]</span><br><span class="line">        chaptername = url[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">yield</span> Request(chapterurl, callback=self.get_chaptercontent, meta=&#123;</span><br><span class="line">            <span class="string">'num'</span>: num,</span><br><span class="line">            <span class="string">'name_id'</span>: response.meta[<span class="string">'name_id'</span>],</span><br><span class="line">            <span class="string">'chapter_url'</span>: chapterurl,</span><br><span class="line">            <span class="string">'chaptername'</span>: chaptername</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chaptercontent</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    item = Content()</span><br><span class="line">    item[<span class="string">'id_name'</span>] = response.meta[<span class="string">'name_id'</span>]</span><br><span class="line">    item[<span class="string">'num'</span>] = response.meta[<span class="string">'num'</span>]</span><br><span class="line">    item[<span class="string">'chapter_url'</span>] = response.meta[<span class="string">'chapter_url'</span>]</span><br><span class="line">    item[<span class="string">'chapter_name'</span>] = response.meta[<span class="string">'chaptername'</span>]</span><br><span class="line">    content = BeautifulSoup(response.text, <span class="string">'lxml'</span>).find(<span class="string">'dd'</span>, id=<span class="string">'contents'</span>).get_text()</span><br><span class="line">    item[<span class="string">'content'</span>] = str(content).replace(<span class="string">'\xa0'</span>, <span class="string">''</span>)</span><br><span class="line">    <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>注意 13\14 行，这个地方返回item是不能用return的哦！用了就结束了，程序就不会继续下去了，得用 yield</p>
<p>下面我们来写存储这部分spider的Pipeline：</p>
<p>数据表：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="string">`dd_chaptername`</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`dd_chaptername`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`xs_chaptername`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`xs_content`</span> <span class="built_in">text</span>,</span><br><span class="line">  <span class="string">`id_name`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`num_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`url`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">2726</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=gb18030;</span><br><span class="line"><span class="keyword">SET</span> FOREIGN_KEY_CHECKS=<span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy13.png" alt=""><br><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy14.png" alt=""></p>
<p>下面是Pipeline：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/scrapy21.png" alt=""></p>
<p>有小伙伴注意，这儿比上面一个Pipeline少一个判断，因为我把判断移动到Spider中去了，这样就可以减少一次Request，减轻服务器压力。</p>
<p>改变后的Spider长这样：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy16.png" alt=""></p>

        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
    <!-- 使用 changyan -->
<div id="changyan-comment">
    <!--PC和WAP自适应版-->
<div id="SOHUCS" sid="2017/09/02/Scrapy-入门/"  ></div>
<script type="text/javascript">
(function(){
var appid = 'cytbPTnjI';
var conf = '96c2d0183701bbf3977fba585925c4ff';
var width = window.innerWidth || document.documentElement.clientWidth;
if (width < 960) {
window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>

</div>
<style>
    #changyan-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2017/09/18/四年之久/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2017/09/02/妹子图爬虫第四弹/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/landscape.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="http://o797mwhn1.bkt.clouddn.com/avatar.jpg" alt="chang's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        liuchangall@163.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    归档
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2018/09/">九月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/07/">七月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/08/">八月 2017<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/07/">七月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/06/">六月 2017<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/05/">五月 2017<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/04/">四月 2017<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/02/">二月 2017<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/01/">一月 2017<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/10/">十月 2016<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/09/">九月 2016<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/08/">八月 2016<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/07/">七月 2016<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/06/">六月 2016<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/05/">五月 2016<span class="sidebar_archives-count">5</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                分类
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                <a class="sidebar_archives-link" href="/categories/Android/">Android<span class="sidebar_archives-count">15</span></a></li><li><a class="sidebar_archives-link" href="/categories/Java/">Java<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/">Python<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/Django/">Django<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/爬虫/">爬虫<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/爬虫/Scrapy/">Scrapy<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/师太/">师太<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/想说的/">想说的<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/摄影/">摄影<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据结构/">数据结构<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/文字/">文字<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/文字/收藏/">收藏<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/生活/">生活<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/算法/">算法<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/编程思想/">编程思想<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/足球/">足球<span class="sidebar_archives-count">2</span></a>
            </ul>
        </li>
        
    

    <!-- Pages  -->
    
        <li>
            <a href="/tags" title="Tags">
                
                    <i class="material-icons sidebar-material-icons">label</i>
                
                Tags
            </a>
        </li>
        
    
        <li>
            <a href="/links" title="Links">
                
                    <i class="material-icons sidebar-material-icons">link</i>
                
                Links
            </a>
        </li>
        
    
        <li>
            <a href="/timeline" title="TimeLine">
                
                    <i class="material-icons sidebar-material-icons">timeline</i>
                
                TimeLine
            </a>
        </li>
        
    
        <li>
            <a href="/about" title="About">
                
                    <i class="material-icons sidebar-material-icons">person</i>
                
                About
            </a>
        </li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                文章总数
                <span class="sidebar-badge">67</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->

    <div class="sidebar-divider"></div>


<!-- Theme Material -->


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    
        <a href="https://twitter.com/Changoall" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter">
                <span class="visuallyhidden">Twitter</span>
            </button><!--
     --></a>
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    
        <a href="http://weibo.com/u/3687003117" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-weibo">
                <span class="visuallyhidden">Weibo</span>
            </button><!--
     --></a>
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/changoal" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    
        <a href="https://www.zhihu.com/people/changoal/activities" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-zhihu">
                <span class="visuallyhidden">Zhihu</span>
            </button><!--
     --></a>
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    
    
    <!-- V2EX -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;2016&nbsp;-<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>changoal
            
                <br>
                
                    <a href="http://www.miitbeian.gov.cn" rel="nofollow">鲁ICP备16022276号</a>
                
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>





    <!-- Leancloud -->
    <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
    <script>
        AV.initialize('8ACGf4QUtP5DVmilmIom41J8-gzGzoHsz', 'irfSS6JU7jIiuECsKUump2q8');
    </script>
    <script type="text/ls-javascript" id="leancloud-views-script">
    function showTime(Counter) {
        var query = new AV.Query(Counter);
        $('.leancloud-views_num').each(function() {
            var url = $(this).attr('id').trim();
            query.equalTo('url', url);
            query.find({
                success: function(results) {
                    if (results.length === 0) {
                        var content = '0 ' + $(document.getElementById(url)).text();
                        $(document.getElementById(url)).text(content);
                        return;
                    }
                    for (var i = 0; i < results.length; i++) {
                        var object = results[i];
                        var content = object.get('time') + ' ' + $(document.getElementById(url)).text();
                        $(document.getElementById(url)).text(content);
                    }
                },
                error: function(object, error) {
                    console.log('Error: ' + error.code + ' ' + error.message);
                }
            });
        });
    }

    function addCount(Counter) {
      var Counter = AV.Object.extend('Counter');
      url = $('.leancloud-views_num').attr('id').trim();
      title = $('.leancloud-views_num').attr('data-flag-title').trim();
      var query = new AV.Query(Counter);
      query.equalTo('url', url);
      query.find({
          success: function(results) {
            if (results.length > 0) {
                var counter = results[0];
                counter.fetchWhenSave(true);
                counter.increment('time');
                counter.save(null, {
                    success: function(counter) {
                        var content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();
                        $(document.getElementById(url)).text(content);
                    },
                    error: function(counter, error) {
                        console.log('Failed to save Visitor num, with error message: ' + error.message);
                    }
                });
            } else {
              var newcounter = new Counter();
              newcounter.set('title', title);
              newcounter.set('url', url);
              newcounter.set('time', 1);
              newcounter.save(null, {
                  success: function(newcounter) {
                      console.log('newcounter.get(\'time\')='+newcounter.get('time'));
                      var content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();
                      $(document.getElementById(url)).text(content);
                  },
                  error: function(newcounter, error) {
                      console.log('Failed to create');
                  }
              });
            }
        },
        error: function(error) {
            console.log('Error:' + error.code + ' ' + error.message);
        }
      });
    }
    $(function() {
        var Counter = AV.Object.extend('Counter');
        if ($('.leancloud-views_num').length === 1) {
            addCount(Counter);
        } else if ($('.post-title-link').length > 1) {
            showTime(Counter);
        }
    });
</script>






   <!-- 畅言公共 js 代码 start -->
<script id="cy_cmt_num" src="https://changyan.sohu.com/upload/plugins/plugins.list.count.js?clientId=cytbPTnjI">
</script>
<!-- 畅言公共 js 代码 end -->





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
    
</script>

<!-- MathJax Load-->


<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
