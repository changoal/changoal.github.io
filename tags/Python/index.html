<!DOCTYPE html>
<html  lang="zh">
<head>
    <meta charset="utf-8">
<title>标签: Python - changoal</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />



    <meta name="description" content="十年之前和现�?">
<meta property="og:type" content="website">
<meta property="og:title" content="changoal">
<meta property="og:url" content="http://yoursite.com/tags/Python/index.html">
<meta property="og:site_name" content="changoal">
<meta property="og:description" content="十年之前和现�?">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="changoal">
<meta name="twitter:description" content="十年之前和现�?">





<link rel="icon" href="/images/icon_round.png">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">
<link rel="stylesheet" href="/css/style.css">


    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">
    

    
    
    
    <style>body{opacity: 0}</style>
    

    
    
    
    


    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-105599788-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-105599788-1');
</script>


    
    
    
    

    


</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/icon_round.png" alt="" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                <a class="navbar-item search" title="搜索" href="javascript:;">
                    <i class="material-icons is-size-5">search</i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns main">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/tags">标签</a></li>
            <li class="is-active"><a href="#" aria-current="page">Python</a></li>
        </ul>
        </nav>
    </div>
</div>

    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-12-17T08:02:14.000Z">
                    2017-12-17</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 分钟 读完 (大约 534 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/12/17/知乎用户基本分析/">
                知乎用户基本分析</a>
            
        </h1>
        <div class="content">
            <h1 id="知乎用户统计"><a href="#知乎用户统计" class="headerlink" title="知乎用户统计"></a>知乎用户统计</h1><p>昨天爬取了知乎大v “朱炫” 的关注者的用户基本信息。</p>
<p><img src="http://o797mwhn1.bkt.clouddn.com/zhuxuan_zhihu.png" alt="image"></p>
<p>如图所示，朱炫总共有 676697 位关注者，半小时爬取了 117913 条用户的基本信息。用户信息里每个用户只有 18 个字段的信息，都是一些很基本的信息，如图<br><img src="http://o797mwhn1.bkt.clouddn.com/json.png" alt="image"></p>
<p>通过 requests 爬取，存进 mongodb 里。下面是一些基本分析：</p>
<h2 id="性别"><a href="#性别" class="headerlink" title="性别"></a>性别</h2><p><img src="http://o797mwhn1.bkt.clouddn.com/gender.png" alt="image"></p>
<p>12万的用户里，男性有 25819 位，女性有 31095 位，还有 60999 位没有设置性别信息。</p>
<h2 id="回答"><a href="#回答" class="headerlink" title="回答"></a>回答</h2><p><img src="http://o797mwhn1.bkt.clouddn.com/answer.png" alt="image"></p>
<p>其中有 63109 位用户从没有回答过问题，32376 位用户回答过 5 个以内的问题，而回答数量超过 50 的只有 2536 位用户。</p>
<h2 id="关注者"><a href="#关注者" class="headerlink" title="关注者"></a>关注者</h2><p><img src="http://o797mwhn1.bkt.clouddn.com/follower.png" alt="image"></p>
<p>有 60749 名用户是没有被任何人关注的，47116 名用户有10个以下的关注者，只有 3349 位用户有50个以上的关注者。</p>
<h2 id="机构号"><a href="#机构号" class="headerlink" title="机构号"></a>机构号</h2><p>在 12w 的关注者里有 29 个机构用号关注了大师兄，只选取了关注者最多的 10 个机构号来显示。</p>
<p><img src="http://o797mwhn1.bkt.clouddn.com/orgs.png" alt="image"></p>
<h2 id="关注者-1"><a href="#关注者-1" class="headerlink" title="关注者"></a>关注者</h2><p>查取了10位关注者最多的用户。<br><img src="http://o797mwhn1.bkt.clouddn.com/top_10.png" alt="image"></p>
<h2 id="有趣"><a href="#有趣" class="headerlink" title="有趣"></a>有趣</h2><h4 id="用的最多的用户名"><a href="#用的最多的用户名" class="headerlink" title="用的最多的用户名"></a>用的最多的用户名</h4><p>你们猜用的最多的用户名是什么？<br><img src="http://o797mwhn1.bkt.clouddn.com/name.png" alt="image"></p>
<p>好像没有一个真名==</p>
<p>用的最多的个人简介是这些：<br><img src="http://o797mwhn1.bkt.clouddn.com/headline.png" alt="image"></p>
<p>看来知乎是学生党的天下。。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>爬虫使用 <code>requests</code>；</p>
<p>数据库是 <code>MongoDB</code>；</p>
<p>绘图用了 <code>matplotlib.pyplot</code> 和 <code>pylab</code></p>
<p>MongoDB 作为非关系型数据库的代表，不用 sql 语句，使用起来确实是方便了一些。</p>
<p>绘图刚学，柱状图的标签还都没有居中==</p>
<p><strong><code>python</code> 是世界上最好用的语言</strong></p>
<p><strong><code>python</code> 是世界上最好用的语言</strong></p>
<p><strong><code>python</code> 是世界上最好用的语言</strong></p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-09-27T16:03:45.000Z">
                    2017-09-28</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/Scrapy/">Scrapy</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    26 分钟 读完 (大约 3957 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/09/28/Scrapy-Spiders/">
                Scrapy Spiders</a>
            
        </h1>
        <div class="content">
            <h1 id="Spiders"><a href="#Spiders" class="headerlink" title="Spiders"></a>Spiders</h1><p>Spider 类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider 就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p>对spider来说，爬取的循环类似下文:</p>
<ol>
<li><p>以初始的 URL 初始化 Request，并设置回调函数。当该 response 下载完毕并返回时，将生成 response ，并作为参数传给该回调函数。spider 中初始的 request 是通过调用 <code>start_requests()</code> 来获取的。 <code>start_requests()</code> 读取    start_urls 中的 URL， 并以 parse 为回调函数生成 Request 。</p>
</li>
<li><p>在回调函数内分析返回的（网页）内容，返回 Item 对象、 dict 、Request 或者一个包含三者的可迭代容器。返回的 Request 对象之后会经过 Scrapy 处理，下载相应的内容，并调用设置的回调函数进行下一步的操作。</p>
</li>
<li><p>在回调函数内，您可以使用 选择器(Selectors) (您也可以使用 BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成 item。</p>
</li>
<li><p>最后，由 spider 返回的 item 将被存到数据库(由某些 Item Pipeline 处理)或使用 Feed exports 存入到文件中。</p>
</li>
</ol>
<p>该循环对任何类型的spider都(多少)适用。</p>
<h2 id="scrapy-Spider"><a href="#scrapy-Spider" class="headerlink" title="scrapy.Spider"></a>scrapy.Spider</h2><p>Spider 是最简单的 spider。每个其他的 spider 必须继承自该类(包括 Scrapy 自带的其他 spider 以及您自己编写的 spider )。 Spider 并没有提供什么特殊的功能。 其仅仅提供了 <code>start_requests()</code> 的默认实现，读取并请求 spider 属性中的 start_urls, 并根据返回的结果(resulting responses)调用 spider 的 parse 方法。</p>
<ul>
<li><p>name</p>
<p>定义 spider 名字的字符串(string)。spider 的名字定义了 Scrapy 如何定位(并初始化) spider，所以其必须是<strong>唯一</strong>的。 不过您可以生成多个相同的 spider 实例(instance)，这没有任何限制。 name 是 spider 最重要的属性，而且是必须的。</p>
<p>如果该 spider 爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加后缀)来命名 spider。 例如，如果 spider 爬取 <code>mywebsite.com</code> ，该 spider 通常会被命名为 <code>mywebsite</code> 。</p>
</li>
<li><p>allowed_domains</p>
<p>可选。包含了 spider 允许爬取的域名(domain)列表(list)。 当 <code>OffsiteMiddleware</code> 启用时， 域名不在列表中的URL不会被跟进。</p>
</li>
<li><p>start_urls</p>
<p>URL 列表。当没有制定特定的 URL 时，spider 将从该列表中开始进行爬取。 因此，第一个被获取到的页面的 URL 将是该列表之一。 后续的URL将会从获取到的数据中提取。就是爬虫的入口网址。</p>
</li>
<li><p>custom_settings</p>
<p>该设置是一个 dict .当启动 spider 时,该设置将会覆盖项目级的设置. 由于设置必须在初始化(instantiation)前被更新,所以该属性 必须定义为 class 属性.</p>
</li>
<li><p>crawler</p>
<p>该属性在初始化 class 后,由类方法 from_crawler() 设置, 并且链接了本 spider 实例对应的 Crawler 对象.</p>
<p>Crawler 包含了很多项目中的组件, 作为单一的入口点 (例如插件,中间件,信号管理器等). </p>
</li>
<li><p>start_requests()</p>
<p>该方法必须返回一个可迭代对象(iterable)。该对象包含了 spider 用于爬取的第一个 Request。</p>
<p>当 spider 启动爬取并且未指定 URL 时，该方法被调用。 当指定了 URL 时，<code>make_requests_from_url()</code> 将被调用来创建 Request 对象。 该方法仅仅会被 Scrapy 调用一次，因此您可以将其实现为生成器。</p>
<p>该方法的默认实现是使用 start_urls 中的 url 生成 Request。</p>
<p>如果您想要修改最初爬取某个网站的 Request 对象，您可以重写(override)该方法。 例如，如果您需要在启动时以 POST 登录某个网站，你可以这么写:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(scrapy.MySpider)</span>:</span></span><br><span class="line">  name = <span class="hljs-string">'myspider'</span></span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_request</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">return</span> [scrapy.FormRequest(<span class="hljs-string">"http://www.example.com/login"</span>,</span><br><span class="line">                                 formdata=&#123;<span class="hljs-string">'user'</span>: <span class="hljs-string">'john'</span>, <span class="hljs-string">'pass'</span>: <span class="hljs-string">'secret'</span>&#125;,</span><br><span class="line">                                 callback=self.logged_in)]</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logged_in</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>make_requests_from_url(url)</p>
<p>该方法接受一个 URL 并返回用于爬取的 Request 对象。 该方法在初始化 request 时被 start_requests() 调用，也被用于转化 url 为 request 。</p>
<p>默认未被复写(overridden)的情况下，该方法返回的 Request 对象中， parse() 作为回调函数，dont_filter 参数也被设置为开启。</p>
</li>
<li><p>parse(response)</p>
<p>当 response 没有指定回调函数时，该方法是 Scrapy 处理下载的 response 的默认函数。</p>
<p>parse 负责处理 response 并返回处理的数据以及(/或)跟进的 URL。 Spider 对其他的 Request 的回调函数也有相同的要求。</p>
<p>该方法及其他的 Request 回调函数必须返回一个包含 Request、dict 或 Item 的可迭代的对象。</p>
</li>
<li><p>log(message[, level, component])</p>
<p>使用 scrapy.log.msg() 方法记录(log)message。 log 中自动带上该 spider 的 name 属性。</p>
</li>
<li><p>closed(reason)</p>
<p>当 spider 关闭时，该函数被调用。 该方法提供了一个替代调用 signals.connect() 来监听 spider_closed 信号的快捷方式。</p>
</li>
</ul>
<h1 id="Spider-arguments"><a href="#Spider-arguments" class="headerlink" title="Spider arguments"></a>Spider arguments</h1><p>Spider arguments are passed through the crawl command using the -a option. For example:</p>
<p><code>scrapy crawl myspider -a category=electronics</code></p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'myspider'</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, category=None, *args, **kwargs)</span>:</span></span><br><span class="line">        super(MySpider, self).__init__(*args, **kwargs)</span><br><span class="line">        self.start_urls = [<span class="hljs-string">'http://www.example.com/categories/%s'</span> % category]</span><br></pre></td></tr></table></figure>
<h1 id="Generic-Spiders"><a href="#Generic-Spiders" class="headerlink" title="Generic Spiders"></a>Generic Spiders</h1><h2 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h2><p><strong>class scrapy.spiders.CrawlSpider</strong></p>
<p>爬取一般网站常用的 spider 。其定义了一些规则(rule)来提供跟进 link 的方便的机制。 也许该 spider 并不是完全适合您的特定网站或项目，但其对很多情况都使用。 因此您可以以其为起点，根据需求修改部分方法。当然您也可以实现自己的 spider。</p>
<p>除了从 Spider 继承过来的(您必须提供的)属性外，其提供了一个新的属性:</p>
<ul>
<li><p>rules</p>
<p>一个包含一个(或多个) Rule 对象的集合(list)。 每个 Rule 对爬取网站的动作定义了特定表现。 Rule 对象在下边会介绍。 如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。</p>
</li>
</ul>
<p>该spider也提供了一个可复写(overrideable)的方法:</p>
<ul>
<li><p>parse_start_url(response)</p>
<p>当start_url的请求返回时，该方法被调用。 该方法分析最初的返回值并必须返回一个 Item 对象或者 一个 Request 对象或者 一个可迭代的包含二者对象。</p>
</li>
</ul>
<h2 id="爬取规则-Crawling-rules"><a href="#爬取规则-Crawling-rules" class="headerlink" title="爬取规则(Crawling rules)"></a>爬取规则(Crawling rules)</h2><p><strong>class scrapy.spiders.Rule(link_extractor, callback=None, cb_kwargs=None, follow=None, process_links=None, process_request=None)</strong></p>
<ul>
<li><p>link_extractor 是一个 <code>Link Extractor</code> 对象。 其定义了如何从爬取到的页面提取链接。</p>
</li>
<li><p>callback 是一个 callable 或 string (该spider中同名的函数将会被调用)。 从 link_extractor 中每获取到链接时将会调用该函数。该回调函数接受一个 response 作为其第一个参数， 并返回一个包含 Item 以及(或) Request 对象(或者这两者的子类)的列表(list)。</p>
</li>
<li><p>cb_kwargs 包含传递给回调函数的参数(keyword argument)的字典。</p>
</li>
<li><p>follow 是一个布尔(boolean)值，指定了根据该规则从 response 提取的链接是否需要跟进。 如果 callback 为None， follow 默认设置为 True ，否则默认为 False 。</p>
</li>
<li><p>process_links 是一个 callable 或 string (该spider中同名的函数将会被调用)。 从 link_extractor 中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p>
</li>
<li><p>process_request 是一个 callable 或 string (该spider中同名的函数将会被调用)。 该规则提取到每个 request 时都会调用该函数。该函数必须返回一个request或者None。 (用来过滤request)</p>
</li>
</ul>
<h2 id="CrawlSpider样例"><a href="#CrawlSpider样例" class="headerlink" title="CrawlSpider样例"></a>CrawlSpider样例</h2><p>接下来给出配合rule使用CrawlSpider的例子:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="hljs-keyword">from</span> scrapy.linkextractors <span class="hljs-keyword">import</span> LinkExtractor</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'myspider'</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="hljs-string">'http://www.example.com'</span>]</span><br><span class="line"></span><br><span class="line">    rules = [</span><br><span class="line">        <span class="hljs-comment"># 提取匹配 'category.php' (但不匹配 'subsection.php') 的链接并跟进链接(没有callback意味着follow默认为True)</span></span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="hljs-string">'category\.php'</span>, ), deny=(<span class="hljs-string">'subsection\.php'</span>, ))),</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># 提取匹配 'item.php' 的链接并使用spider的parse_item方法进行分析</span></span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="hljs-string">'item\.php'</span>, )), callback=<span class="hljs-string">'parse_item'</span>),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_item</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        self.logger.info(<span class="hljs-string">'Hi, this is an item page! %s'</span>, response.url)</span><br><span class="line"></span><br><span class="line">        item = scrapy.Item()</span><br><span class="line">        item[<span class="hljs-string">'id'</span>] = response.xpath(<span class="hljs-string">'//td[@id="item_id"]/text()'</span>).re(<span class="hljs-string">r'ID: (\d+)'</span>)</span><br><span class="line">        item[<span class="hljs-string">'name'</span>] = response.xpath(<span class="hljs-string">'//td[@id="item_name"]/text()'</span>).extract()</span><br><span class="line">        item[<span class="hljs-string">'description'</span>] = response.xpath(<span class="hljs-string">'//td[@id="item_description"]/text()'</span>).extract()</span><br><span class="line">        <span class="hljs-keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>该 spider 将从 example.com 的首页开始爬取，获取 category 以及 item 的链接并对后者使用 parse_item 方法。 当 item 获得返回(response)时，将使用 XPath 处理 HTML 并生成一些数据填入 Item 中。</p>
<h2 id="XMLFeedSpider"><a href="#XMLFeedSpider" class="headerlink" title="XMLFeedSpider"></a>XMLFeedSpider</h2><p><strong>class scrapy.spiders.XMLFeedSpider</strong></p>
<p>XMLFeedSpider 被设计用于通过迭代各个节点来分析 XML 源(XML feed)。 迭代器可以从 iternodes ， xml ， html 选择。 鉴于 xml 以及 html 迭代器需要先读取所有DOM再分析而引起的性能问题， 一般还是推荐使用 iternodes 。 不过使用 html 作为迭代器能有效应对错误的 XML。</p>
<p>您必须定义下列类属性来设置迭代器以及标签名(tag name):</p>
<ul>
<li><p>iterator</p>
<p>用于确定使用哪个迭代器的string。可选项有:</p>
<ul>
<li><code>iternodes</code> - 一个高性能的基于正则表达式的迭代器</li>
<li><code>html</code> - 使用 Selector 的迭代器。 需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存， 当数据量大的时候会产生问题。</li>
<li><code>xml</code> - 使用 Selector 的迭代器。 需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存， 当数据量大的时候会产生问题。</li>
</ul>
<p>默认值为 <code>iternodes</code> 。</p>
</li>
<li><p>itertag</p>
<p>一个包含开始迭代的节点名的string。例如:<br><code>itertag = &#39;product&#39;</code></p>
</li>
<li><p>namespaces</p>
<p>一个由 (prefix, url) 元组(tuple)所组成的 list。 其定义了在该文档中会被 spider 处理的可用的 namespace 。 prefix 及 uri 会被自动调用 register_namespace() 生成 namespace。</p>
<p>您可以通过在 itertag 属性中制定节点的 namespace。</p>
<p>例如:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">YourSpider</span><span class="hljs-params">(XMLFeedSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">  namespaces = [(<span class="hljs-string">'n'</span>, <span class="hljs-string">'http://www.sitemaps.org/schemas/sitemap/0.9'</span>)]</span><br><span class="line">  itertag = <span class="hljs-string">'n:url'</span></span><br><span class="line">  <span class="hljs-comment"># ...</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>除了这些新的属性之外，该spider也有以下可以覆盖(overrideable)的方法:</p>
<ul>
<li><p>adapt_response(response)</p>
<p>该方法在 spider 分析 response 前被调用。您可以在 response 被分析之前使用该函数来修改内容(body)。 该方法接受一个 response 并返回一个 response (可以相同也可以不同)。</p>
</li>
<li><p>parse_node(response, selector)</p>
<p>当节点符合提供的标签名时(itertag)该方法被调用。 接收到的 response 以及相应的 Selector 作为参数传递给该方法。 该方法返回一个 Item 对象或者 Request 对象 或者一个包含二者的可迭代对象(iterable)。</p>
</li>
<li><p>process_results(response, results)</p>
<p>当 spider 返回结果(item或request)时该方法被调用。 设定该方法的目的是在结果返回给框架核心(framework core)之前做最后的处理， 例如设定 item 的 ID 。其接受一个结果的列表(list of results)及对应的 response。 其结果必须返回一个结果的列表(list of results)(包含Item或者Request对象)。</p>
</li>
</ul>
<h2 id="XMLFeedSpider例子"><a href="#XMLFeedSpider例子" class="headerlink" title="XMLFeedSpider例子"></a>XMLFeedSpider例子</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> XmlFeedSpider</span><br><span class="line"><span class="hljs-keyword">from</span> myproject.items <span class="hljs-keyword">import</span> TestItem</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(XmlFeedSpider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="hljs-string">'http://www.example.com/feed.xml'</span>]</span><br><span class="line">    iterator = <span class="hljs-string">'iternodes'</span> <span class="hljs-comment"># This is actually unnecessary, since it's the default value</span></span><br><span class="line">    itertag = <span class="hljs-string">'item'</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_node</span><span class="hljs-params">(self, response, node)</span>:</span></span><br><span class="line">        self.logger.info(<span class="hljs-string">'Hi, this is a &lt;%s&gt; node!: %s'</span>, self.itertag, <span class="hljs-string">''</span>.join(node.extract()))</span><br><span class="line"></span><br><span class="line">        item = TestItem()</span><br><span class="line">        item[<span class="hljs-string">'id'</span>] = node.xpath(<span class="hljs-string">'@id'</span>).extract()</span><br><span class="line">        item[<span class="hljs-string">'name'</span>] = node.xpath(<span class="hljs-string">'name'</span>).extract()</span><br><span class="line">        item[<span class="hljs-string">'description'</span>] = node.xpath(<span class="hljs-string">'description'</span>).extract()</span><br><span class="line">        <span class="hljs-keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>简单来说，我们在这里创建了一个 spider ，从给定的 start_urls 中下载 feed ， 并迭代 feed 中每个 item 标签，输出，并在 Item 中存储有些随机数据。</p>
<h2 id="CSVFeedSpider"><a href="#CSVFeedSpider" class="headerlink" title="CSVFeedSpider"></a>CSVFeedSpider</h2><p><strong>class scrapy.spiders.CSVFeedSpider</strong></p>
<p>该 spider 除了其按行遍历而不是节点之外其他和 XMLFeedSpider 十分类似。 而其在每次迭代时调用的是 parse_row() 。</p>
<ul>
<li><p>delimiter<br>在CSV文件中用于区分字段的分隔符。类型为string。 默认为 ‘,’ (逗号)。</p>
</li>
<li><p>quotechar<br>A string with the enclosure character for each field in the CSV file Defaults to ‘“‘ (quotation mark).</p>
</li>
<li><p>headers<br>在CSV文件中包含的用来提取字段的行的列表。参考下边的例子。</p>
</li>
<li><p>parse_row(response, row)<br>该方法接收一个 response 对象及一个以提供或检测出来的 header 为键的字典(代表每行)。 该 spider 中，您也可以覆盖  adapt_response 及 process_results 方法来进行预处理(pre-processing)及后(post-processing)处理。</p>
</li>
</ul>
<h2 id="CSVFeedSpider例子"><a href="#CSVFeedSpider例子" class="headerlink" title="CSVFeedSpider例子"></a>CSVFeedSpider例子</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> CSVFeedSpider</span><br><span class="line"><span class="hljs-keyword">from</span> myproject.items <span class="hljs-keyword">import</span> TestItem</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(CSVFeedSpider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="hljs-string">'http://www.example.com/feed.csv'</span>]</span><br><span class="line">    delimiter = <span class="hljs-string">';'</span></span><br><span class="line">    quotechar = <span class="hljs-string">"'"</span></span><br><span class="line">    headers = [<span class="hljs-string">'id'</span>, <span class="hljs-string">'name'</span>, <span class="hljs-string">'description'</span>]</span><br><span class="line"></span><br><span class="line">     <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_row</span><span class="hljs-params">(self, response, row)</span>:</span></span><br><span class="line">            self.logger.info(<span class="hljs-string">'Hi, this is a row!: %r'</span>, row)</span><br><span class="line"></span><br><span class="line">        item = TestItem()</span><br><span class="line">        item[<span class="hljs-string">'id'</span>] = row[<span class="hljs-string">'id'</span>]</span><br><span class="line">        item[<span class="hljs-string">'name'</span>] = row[<span class="hljs-string">'name'</span>]</span><br><span class="line">        item[<span class="hljs-string">'description'</span>] = row[<span class="hljs-string">'description'</span>]</span><br><span class="line">        <span class="hljs-keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h2 id="SitemapSpider"><a href="#SitemapSpider" class="headerlink" title="SitemapSpider"></a>SitemapSpider</h2><p><strong>class scrapy.spiders.SitemapSpider</strong></p>
<p>SitemapSpider 使您爬取网站时可以通过 Sitemaps 来发现爬取的URL。</p>
<p>其支持嵌套的 sitemap，并能从 robots.txt 中获取 sitemap 的url。</p>
<ul>
<li><p>sitemap_urls<br>包含您要爬取的 url 的 sitemap 的 url 列表(list)。 您也可以指定为一个 robots.txt ，spider 会从中分析并提取url。</p>
</li>
<li><p>sitemap_rules<br>一个包含 <code>(regex, callback)</code> 元组的列表(list):</p>
<ul>
<li><p>regex 是一个用于匹配从sitemap提供的url的正则表达式。 regex 可以是一个字符串或者编译的正则对象(compiled regex object)。</p>
</li>
<li><p>callback指定了匹配正则表达式的url的处理函数。 callback 可以是一个字符串(spider中方法的名字)或者是callable。</p>
</li>
</ul>
<p>例如:<code>sitemap_rules = [(&#39;/product/&#39;, &#39;parse_product&#39;)]</code></p>
<p>规则按顺序进行匹配，之后第一个匹配才会被应用。</p>
<p>如果您忽略该属性，sitemap中发现的所有url将会被 parse 函数处理。</p>
</li>
<li><p>sitemap_follow</p>
<p>一个用于匹配要跟进的sitemap的正则表达式的列表(list)。其仅仅被应用在使用 Sitemap index files 来指向其他 sitemap文件的站点。</p>
<p>默认情况下所有的 sitemap 都会被跟进。</p>
</li>
<li><p>sitemap_alternate_links</p>
<p>指定当一个 url 有可选的链接时，是否跟进。 有些非英文网站会在一个 url 块内提供其他语言的网站链接。</p>
<p>例如:</p>
<figure class="highlight xml hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;<span class="hljs-name">loc</span>&gt;</span>http://example.com/<span class="hljs-tag">&lt;/<span class="hljs-name">loc</span>&gt;</span></span><br><span class="line">  <span class="hljs-tag">&lt;<span class="hljs-name">xhtml:link</span> <span class="hljs-attr">rel</span>=<span class="hljs-string">"alternate"</span> <span class="hljs-attr">hreflang</span>=<span class="hljs-string">"de"</span> <span class="hljs-attr">href</span>=<span class="hljs-string">"http://example.com/de"</span>/&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>当 <code>sitemap_alternate_links</code> 设置时，两个 URL 都会被获取。 当 <code>sitemap_alternate_links</code> 关闭时，只有 <code>http://example.com/</code> 会被获取。</p>
<p>默认 <code>sitemap_alternate_links</code> 关闭。</p>
</li>
<li><p>SitemapSpider样例</p>
<p>简单的例子: 使用 parse 处理通过sitemap发现的所有url:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> SitemapSpider</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(SitemapSpider)</span>:</span></span><br><span class="line">  sitemap_urls = [<span class="hljs-string">'http://www.example.com/sitemap.xml'</span>]</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape item here ...</span></span><br></pre></td></tr></table></figure>
<p>用特定的函数处理某些url，其他的使用另外的callback:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> SitemapSpider</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(SitemapSpider)</span>:</span></span><br><span class="line">  sitemap_urls = [<span class="hljs-string">'http://www.example.com/sitemap.xml'</span>]</span><br><span class="line">  sitemap_rules = [</span><br><span class="line">      (<span class="hljs-string">'/product/'</span>, <span class="hljs-string">'parse_product'</span>),</span><br><span class="line">      (<span class="hljs-string">'/category/'</span>, <span class="hljs-string">'parse_category'</span>),</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_product</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape product ...</span></span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_category</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape category ...</span></span><br></pre></td></tr></table></figure>
<p>跟进 robots.txt 文件定义的 sitemap 并只跟进包含有 ..sitemap_shop 的 url:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> SitemapSpider</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(SitemapSpider)</span>:</span></span><br><span class="line">  sitemap_urls = [<span class="hljs-string">'http://www.example.com/robots.txt'</span>]</span><br><span class="line">  sitemap_rules = [</span><br><span class="line">      (<span class="hljs-string">'/shop/'</span>, <span class="hljs-string">'parse_shop'</span>),</span><br><span class="line">  ]</span><br><span class="line">  sitemap_follow = [<span class="hljs-string">'/sitemap_shops'</span>]</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_shop</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape shop here ...</span></span><br></pre></td></tr></table></figure>
<p>在SitemapSpider中使用其他url:</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.spiders <span class="hljs-keyword">import</span> SitemapSpider</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MySpider</span><span class="hljs-params">(SitemapSpider)</span>:</span></span><br><span class="line">  sitemap_urls = [<span class="hljs-string">'http://www.example.com/robots.txt'</span>]</span><br><span class="line">  sitemap_rules = [</span><br><span class="line">      (<span class="hljs-string">'/shop/'</span>, <span class="hljs-string">'parse_shop'</span>),</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">  other_urls = [<span class="hljs-string">'http://www.example.com/about'</span>]</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">      requests = list(super(MySpider, self).start_requests())</span><br><span class="line">      requests += [scrapy.Request(x, self.parse_other) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> self.other_urls]</span><br><span class="line">      <span class="hljs-keyword">return</span> requests</span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_shop</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape shop here ...</span></span><br><span class="line"></span><br><span class="line">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_other</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">      <span class="hljs-keyword">pass</span> <span class="hljs-comment"># ... scrape other here ...</span></span><br></pre></td></tr></table></figure>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-09-27T13:46:19.000Z">
                    2017-09-27</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/Scrapy/">Scrapy</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    8 分钟 读完 (大约 1269 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/09/27/Scrapy命令行/">
                Scrapy命令行</a>
            
        </h1>
        <div class="content">
            <h2 id="新建项目"><a href="#新建项目" class="headerlink" title="新建项目"></a>新建项目</h2><p><code>scrapy startproject Demo</code></p>
<p>该命令会在当前目录下建立一个名为 Demo 的 scrapy 项目</p>
<h2 id="控制项目"><a href="#控制项目" class="headerlink" title="控制项目"></a>控制项目</h2><p><code>cd Demo</code> 进入到项目目录中</p>
<p><code>scrapy genspider changoal changoal.cn</code><br>创建一个新的 spider，该命令会在 spiders 文件夹下新建一个叫 changoal.py 的文件。文件里有以下内容：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ChangoalSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">"changoal"</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">"changoal.cn"</span>]</span><br><span class="line">    start_urls = [<span class="hljs-string">'http://changoal.cn/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<h2 id="可用的工具命令"><a href="#可用的工具命令" class="headerlink" title="可用的工具命令"></a>可用的工具命令</h2><p><code>scrapy -h</code> 可以查看所有可用的命令。</p>
<p>Scrapy提供了两种类型的命令。一种必须在Scrapy项目中运行(针对项目(Project-specific)的命令)，另外一种则不需要(全局命令)。全局命令在项目中运行时的表现可能会与在非项目中运行有些许差别(因为可能会使用项目的设定)。</p>
<p>全局命令：</p>
<ul>
<li><code>startproject</code> </li>
<li><code>settings</code> </li>
<li><code>runspider</code> </li>
<li><code>shell</code> </li>
<li><code>fetch</code> </li>
<li><code>view</code> </li>
<li><code>version</code> </li>
</ul>
<p>项目(Project-only)命令:</p>
<ul>
<li><code>crawl</code></li>
<li><code>check</code> </li>
<li><code>list</code> </li>
<li><code>edit</code> </li>
<li><code>parse</code></li>
<li><code>genspider</code> </li>
<li><code>bench</code>   </li>
</ul>
<h3 id="startproject"><a href="#startproject" class="headerlink" title="startproject"></a>startproject</h3><ul>
<li>语法: <code>scrapy startproject &lt;project_name&gt;</code></li>
<li>是否需要项目: no</li>
</ul>
<p>在 <code>project_name</code> 文件夹下创建一个名为 <code>myproject</code> 的 Scrapy 项目。<br><code>scrapy startproject myproject</code></p>
<h3 id="genspider"><a href="#genspider" class="headerlink" title="genspider"></a>genspider</h3><ul>
<li>语法: <code>scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;</code></li>
<li>是否需要项目: yes</li>
</ul>
<p>在当前项目中创建spider。</p>
<p>这仅仅是创建spider的一种快捷方法。该方法可以使用提前定义好的模板来生成spider。您也可以自己创建spider的源码文件。</p>
<p>例子:<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider -l</span><br><span class="line">Available templates:</span><br><span class="line">  basic</span><br><span class="line">  crawl</span><br><span class="line">  csvfeed</span><br><span class="line">  xmlfeed</span><br><span class="line"></span><br><span class="line">$ scrapy genspider -d basic</span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class $classname(scrapy.Spider):</span><br><span class="line">    name = &quot;$name&quot;</span><br><span class="line">    allowed_domains = [&quot;$domain&quot;]</span><br><span class="line">    start_urls = (</span><br><span class="line">        &apos;http://www.$domain/&apos;,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">$ scrapy genspider -t basic example example.com</span><br><span class="line">Created spider &apos;example&apos; using template &apos;basic&apos; in module:</span><br><span class="line">  mybot.spiders.example</span><br></pre></td></tr></table></figure></p>
<h3 id="crawl"><a href="#crawl" class="headerlink" title="crawl"></a>crawl</h3><ul>
<li>语法:<code>scrapy crawl &lt;spider&gt;</code></li>
<li>是否需要项目: yes</li>
</ul>
<p>使用spider进行爬取。<br><code>scrapy crawl myspider</code></p>
<h3 id="check"><a href="#check" class="headerlink" title="check"></a>check</h3><ul>
<li>语法: <code>scrapy check [-l] &lt;spider&gt;</code></li>
<li>是否需要项目: yes</li>
</ul>
<p>运行contract检查。(不懂有什么用)<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy check -l</span><br><span class="line">first_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line">second_spider</span><br><span class="line">  * parse</span><br><span class="line">  * parse_item</span><br><span class="line"></span><br><span class="line">$ scrapy check</span><br><span class="line">[FAILED] first_spider:parse_item</span><br><span class="line">&gt;&gt;&gt; &apos;RetailPricex&apos; field is missing</span><br><span class="line"></span><br><span class="line">[FAILED] first_spider:parse</span><br><span class="line">&gt;&gt;&gt; Returned 92 requests, expected 0..4</span><br></pre></td></tr></table></figure></p>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><ul>
<li>语法: <code>scrapy list</code></li>
<li>是否需要项目: yes</li>
</ul>
<p>列出当前项目中所有可用的spider。每行输出一个spider。</p>
<h3 id="edit"><a href="#edit" class="headerlink" title="edit"></a>edit</h3><ul>
<li>语法: <code>scrapy edit &lt;spider&gt;</code></li>
<li>是否需要项目: yes<br>使用 EDITOR 中设定的编辑器编辑给定的spider</li>
</ul>
<p>该命令仅仅是提供一个快捷方式。开发者可以自由选择其他工具或者IDE来编写调试spider。</p>
<h3 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h3><ul>
<li>语法: <code>scrapy fetch &lt;url&gt;</code></li>
<li>是否需要项目: no</li>
</ul>
<p>使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容送到标准输出。</p>
<p>该命令以spider下载页面的方式获取页面。例如，如果spider有 USER_AGENT 属性修改了 User Agent，该命令将会使用该属性。</p>
<p>因此，您可以使用该命令来查看spider如何获取某个特定页面。</p>
<p>该命令如果非项目中运行则会使用默认Scrapy downloader设定。</p>
<p><code>scrapy fetch http://www.changoal.cn</code></p>
<h3 id="view"><a href="#view" class="headerlink" title="view"></a>view</h3><ul>
<li>语法: <code>scrapy view &lt;url&gt;</code></li>
<li>是否需要项目: no</li>
</ul>
<p>在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 有些时候spider获取到的页面和普通用户看到的并不相同。因此该命令可以用来检查spider所获取到的页面，并确认这是您所期望的。</p>
<p><code>scrapy view http://www.changoal.cn</code></p>
<h3 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h3><ul>
<li>语法: <code>scrapy shell [url]</code></li>
<li>是否需要项目: no</li>
</ul>
<p>以给定的URL(如果给出)或者空(没有给出URL)启动Scrapy shell。</p>
<p><code>scrapy shell http://www.changoal.cn</code></p>
<h3 id="parse"><a href="#parse" class="headerlink" title="parse"></a>parse</h3><ul>
<li>语法: <code>scrapy parse &lt;url&gt; [options]</code></li>
<li>是否需要项目: yes</li>
</ul>
<p>获取给定的URL并使用相应的 spider 分析处理。如果您提供 <code>--callback</code> 选项，则使用 spider 的该方法处理，否则使用 <code>parse</code> 。</p>
<p>支持的选项:</p>
<ul>
<li><code>--spider=SPIDER</code>: 跳过自动检测spider并强制使用特定的spider</li>
<li><code>--a NAME=VALUE</code>: 设置spider的参数(可能被重复)</li>
<li><code>--callback</code> or <code>-c</code>: spider中用于解析返回(response)的回调函数</li>
<li><code>--pipelines</code>: 在pipeline中处理item</li>
<li><code>--rules</code> or <code>-r</code>: 使用 CrawlSpider 规则来发现用来解析返回(response)的回调函数</li>
<li><code>--noitem</code>s: 不显示爬取到的item</li>
<li><code>--nolinks</code>: 不显示提取到的链接</li>
<li><code>--nocolour</code>: 避免使用pygments对输出着色</li>
<li><code>--depth</code> or <code>-d</code>: 指定跟进链接请求的层次数(默认: 1)</li>
<li><code>--verbose</code> or <code>-v</code>: 显示每个请求的详细信息</li>
</ul>
<h3 id="settings"><a href="#settings" class="headerlink" title="settings"></a>settings</h3><ul>
<li>语法: <code>scrapy settings [options]</code></li>
<li>是否需要项目: no</li>
</ul>
<p>获取Scrapy的设定。</p>
<p>在项目中运行时，该命令将会输出项目的设定值，否则输出Scrapy默认设定。</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy settings --get BOT_NAME</span><br><span class="line">scrapybot</span><br><span class="line">$ scrapy settings --get DOWNLOAD_DELAY</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h3 id="runspider"><a href="#runspider" class="headerlink" title="runspider"></a>runspider</h3><ul>
<li>语法: <code>scrapy runspider &lt;spider_file.py&gt;</code></li>
<li>是否需要项目: no</li>
</ul>
<p>在未创建项目的情况下，运行一个编写在Python文件中的spider。</p>
<p><code>scrapy runspider myspider.py</code></p>
<h3 id="version"><a href="#version" class="headerlink" title="version"></a>version</h3><ul>
<li>语法: <code>scrapy version [-v]</code></li>
<li>是否需要项目: no</li>
</ul>
<p>输出Scrapy版本。配合 -v 运行时，该命令同时输出Python, Twisted以及平台的信息，方便bug提交。</p>
<h3 id="自定义项目命令"><a href="#自定义项目命令" class="headerlink" title="自定义项目命令"></a>自定义项目命令</h3><p>您也可以通过 <code>COMMANDS_MODULE</code> 来添加您自己的项目命令。您可以以 <code>scrapy/commands</code> 中 <code>Scrapy commands</code> 为例来了解如何实现您的命令。</p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-09-02T13:19:00.000Z">
                    2017-09-02</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    24 分钟 读完 (大约 3561 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/09/02/Scrapy-入门/">
                Scrapy 入门</a>
            
        </h1>
        <div class="content">
            <h1 id="scrapy-介绍"><a href="#scrapy-介绍" class="headerlink" title="scrapy 介绍"></a>scrapy 介绍</h1><p>scrapy 是一个基于 Python 语言的爬虫框架。有了框架的存在，我们可以更方便的爬虫了，框架帮我们封装好了下载等模块，而且更重要的是框架使用了异步的模式，加快了爬虫的速度。</p>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>在命令行中执行 <code>conda install Scrapy</code> 这样就安装好了 Scrapy 模块，是不是特别简单。ahahahha</p>
<h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>接下来就要开始我们的 scrapy 之路了。</p>
<h2 id="新建项目"><a href="#新建项目" class="headerlink" title="新建项目"></a>新建项目</h2><p>使用 Scrapy 第一步：创建项目，命令行进入你需要放置项目的目录，然后执行</p>
<p> <code>scrapy startproject ScrapyDemo   #ScrapyDemo是项目名称</code> </p>
<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>这时会在目录下多出一个 ScrapyDemo 文件夹，这就是 Scrapy 项目了，项目的结构如下<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">|-- ScrapyDemo</span><br><span class="line">|   `-- ScrapyDemo</span><br><span class="line">|       |-- spiders</span><br><span class="line">|       |   `-- __init__.py</span><br><span class="line">|       |-- __init__.py</span><br><span class="line">|       |-- items.py</span><br><span class="line">|       |-- middlewares.py</span><br><span class="line">|       |-- pipelines.py</span><br><span class="line">|       `-- settings.py</span><br><span class="line">`-- scrapy.cfg</span><br></pre></td></tr></table></figure></p>
<p>目录说明：</p>
<ul>
<li>ScrapyDemo(外层) 项目总目录</li>
<li>ScrapyDemo(内层) 项目目录</li>
<li>scrapy.cfg 项目的配置文件</li>
<li>spiders 放置我们的爬虫代码的目录</li>
<li>items.py 定义我们需要获取的字段</li>
<li>middlewares.py </li>
<li>pipelines.py 用来定义存储</li>
<li>settings.py 项目设置文件</li>
</ul>
<p>还有一点要注意的是，Scrapy 默认是不能在 IDE 中调试的，所以要在项目总目录下新建一个 entrypoint.py 文件，写下以下内容：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scrapy.cmdline <span class="hljs-keyword">import</span> execute</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 前两个参数是不变的，第三个参数是自己定义的 spider 的名字</span></span><br><span class="line">execute([<span class="hljs-string">'scrapy'</span>, <span class="hljs-string">'crawl'</span>, <span class="hljs-string">'dingdian'</span>])</span><br></pre></td></tr></table></figure></p>
<p>现在整个目录应该是这样（盗图..）</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/11/%E5%BF%AB%E6%8D%B7%E5%90%AF%E5%8A%A8.png" alt=""></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下面我们先来看一下框架的架构图</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/scrapy_architecture.png" alt=""></p>
<blockquote>
<p>Scrapy Engine: 这是引擎，负责Spiders、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等等！（像不像人的身体？）</p>
<p>Scheduler(调度器): 它负责接受引擎发送过来的requests请求，并按照一定的方式进行整理排列，入队、并等待Scrapy Engine(引擎)来请求时，交给引擎。</p>
<p>Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spiders来处理，</p>
<p>Spiders：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</p>
<p>Item Pipeline：它负责处理Spiders中获取到的Item，并进行处理，比如去重，持久化存储（存数据库，写入文件，总之就是保存数据用的）</p>
<p>Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件</p>
<p>Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spiders中间‘通信’的功能组件（比如进入Spiders的Responses;和从Spiders出去的Requests）</p>
</blockquote>
<p>数据在整个Scrapy的流向：</p>
<blockquote>
<p>程序运行的时候，</p>
<p>引擎：Hi！Spider, 你要处理哪一个网站？</p>
<p>Spiders：我要处理23wx.com</p>
<p>引擎：你把第一个需要的处理的URL给我吧。</p>
<p>Spiders：给你第一个URL是XXXXXXX.com</p>
<p>引擎：Hi！调度器，我这有request你帮我排序入队一下。</p>
<p>调度器：好的，正在处理你等一下。</p>
<p>引擎：Hi！调度器，把你处理好的request给我，</p>
<p>调度器：给你，这是我处理好的request</p>
<p>引擎：Hi！下载器，你按照下载中间件的设置帮我下载一下这个request</p>
<p>下载器：好的！给你，这是下载好的东西。（如果失败：不好意思，这个request下载失败，然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载。）</p>
<p>引擎：Hi！Spiders，这是下载好的东西，并且已经按照Spider中间件处理过了，你处理一下（注意！这儿responses默认是交给def parse这个函数处理的）</p>
<p>Spiders：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，这是我需要跟进的URL，将它的responses交给函数 def  xxxx(self, responses)处理。还有这是我获取到的Item。</p>
<p>引擎：Hi ！Item Pipeline 我这儿有个item你帮我处理一下！调度器！这是我需要的URL你帮我处理下。然后从第四步开始循环，直到获取到你需要的信息，</p>
<p>注意！只有当调度器中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的 URL，Scrapy会重新下载。）</p>
</blockquote>
<h2 id="写代码"><a href="#写代码" class="headerlink" title="写代码"></a>写代码</h2><p>建立一个项目之后：</p>
<p>第一件事就是在 items.py 文件中定义我们需要的字段，用来临时存储要保存的数据，方便以后数据的持久化存储，比如 数据库 文本文件等。</p>
<p>第二件事是在 spiders.py 中编写自己的爬虫代码</p>
<p>第三件事是在 pipelines.py 中存储自己的数据</p>
<p><strong>建议：在大家调试的时候在settings.py中取消下面几行的注释：</strong><br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HTTPCACHE_ENABLED = <span class="hljs-keyword">True</span></span><br><span class="line">HTTPCACHE_EXPIRATION_SECS = <span class="hljs-number">0</span></span><br><span class="line">HTTPCACHE_DIR = <span class="hljs-string">'httpcache'</span></span><br><span class="line">HTTPCACHE_IGNORE_HTTP_CODES = []</span><br><span class="line">HTTPCACHE_STORAGE = <span class="hljs-string">'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br></pre></td></tr></table></figure></p>
<p>上面代码的作用是 Scrapy 会缓存你有的 Requests！ 当你再次请求时，如果存在缓存文档则返回缓存文档，而不是去网站请求，这样既加快了本地调试速度，也减轻了 网站的压力。一举多得</p>
<h3 id="定义字段"><a href="#定义字段" class="headerlink" title="定义字段"></a>定义字段</h3><p>要根据自己要爬取的内容来定义字段。比如，在这里我们要爬的是小说站点就需要定义，小说名字，作者，小说地址，连载状态，字数，文章类别 等字段。</p>
<p>就像下面这样：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ScrapydemoItem</span><span class="hljs-params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="hljs-comment"># 小说名字</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 作者</span></span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 小说地址</span></span><br><span class="line">    novelurl = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 连载状态</span></span><br><span class="line">    serialstatus = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 连载字数</span></span><br><span class="line">    serialnumber = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 类别</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 编号</span></span><br><span class="line">    novel_id = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<h3 id="编写-spider"><a href="#编写-spider" class="headerlink" title="编写 spider"></a>编写 spider</h3><p>在 spiders 目录下新建一个 ScrapyDemo.py 文件，并导入我们需用的模块</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy </span><br><span class="line"><span class="hljs-keyword">import</span> re</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> Request</span><br><span class="line"><span class="hljs-keyword">from</span> ScrapyDemo.items <span class="hljs-keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Muspider</span><span class="hljs-params">(scrapy.Spider)</span>:</span></span><br></pre></td></tr></table></figure>
<p>我们需要从一个地址入手开始爬取，我在顶点小说上没有发现有全站小说地址，但是我找到每个分类地址全部小说：</p>
<p>玄幻魔幻：<a href="http://www.x23us.com/class/1_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/1_1.html</a></p>
<p>武侠修真：<a href="http://www.x23us.com/class/2_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/2_1.html</a></p>
<p>都市言情：<a href="http://www.x23us.com/class/3_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/3_1.html</a></p>
<p>历史军事：<a href="http://www.x23us.com/class/4_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/4_1.html</a></p>
<p>侦探推理：<a href="http://www.x23us.com/class/5_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/5_1.html</a></p>
<p>网游动漫：<a href="http://www.x23us.com/class/6_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/6_1.html</a></p>
<p>科幻小说：<a href="http://www.x23us.com/class/7_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/7_1.html</a></p>
<p>恐怖灵异：<a href="http://www.x23us.com/class/8_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/8_1.html</a></p>
<p>散文诗词：<a href="http://www.x23us.com/class/9_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/9_1.html</a></p>
<p>其他：<a href="http://www.x23us.com/class/10_1.html" target="_blank" rel="noopener">http://www.x23us.com/class/10_1.html</a></p>
<p>全本：<a href="http://www.x23us.com/quanben/1" target="_blank" rel="noopener">http://www.x23us.com/quanben/1</a></p>
<p>好啦！入口地址我们找到了，现在开始写第一部分代码：</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"><span class="hljs-keyword">import</span> re</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> Request</span><br><span class="line"><span class="hljs-keyword">from</span> ScrapyDemo.items <span class="hljs-keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Myspider</span><span class="hljs-params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'ScrapyDemo'</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">'x23us.com'</span>]</span><br><span class="line">    bash_url = <span class="hljs-string">'http://www.x23us.com/class/'</span></span><br><span class="line">    bashurl = <span class="hljs-string">'.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>):</span><br><span class="line">            url = self.bash_url + str(i) + <span class="hljs-string">'_1'</span> + self.bashurl</span><br><span class="line">            <span class="hljs-keyword">yield</span> Request(url,self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        print(response.text)</span><br></pre></td></tr></table></figure>
<p>首先我们创建一个类 Myspider；这个类继承自 scrapy.Spider</p>
<p>定义了一个 allowed_domains ；这个不是必须的；但是在某写情况下需要用得到，比如使用爬取规则的时候就需要了；它的作用是只会跟进存在于 allowed_domains 中的 URL。不存在的 URL 会被忽略。</p>
<p><strong>第九行定义的 name 是之前我们在 entrypoint.py 文件中的第三个参数 此 name 在整个项目中有且只能有一个、名字不可重复！！！</strong></p>
<p>之后可以运行 entrypoint.py 文件来检查一下代码时候可以正常工作。</p>
<p>请求就这么轻而易举的实现了啊！简直So Easy！</p>
<p>继续 继续！</p>
<p>我们需要历遍所有页面才能取得所有的小说页面连接：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/11/%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B52.png" alt=""></p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"><span class="hljs-keyword">import</span> re</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> Request</span><br><span class="line"><span class="hljs-keyword">from</span> ScrapyDemo.items <span class="hljs-keyword">import</span> ScrapydemoItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Muspider</span><span class="hljs-params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="hljs-string">'ScrapyDemo'</span></span><br><span class="line">    allowed_domains = [<span class="hljs-string">'x23us.com'</span>]</span><br><span class="line">    bash_url = <span class="hljs-string">'http://www.x23us.com/class/'</span></span><br><span class="line">    bashurl = <span class="hljs-string">'.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>):</span><br><span class="line">            url = self.bash_url + str(i) + <span class="hljs-string">'_1'</span> + self.bashurl</span><br><span class="line">            <span class="hljs-keyword">yield</span> Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        max_span = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'pagelink'</span>).find_all(<span class="hljs-string">'a'</span>)[<span class="hljs-number">-1</span>].get_text()</span><br><span class="line">        bashurl = str(response.url)[:<span class="hljs-number">-6</span>]</span><br><span class="line">        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">            url = bashurl + str(num) + self.bashurl</span><br><span class="line">            <span class="hljs-keyword">yield</span> Request(url, self.get_name)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_name</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        novels = BeautifulSoup(str(response), <span class="hljs-string">'lxml'</span>).find_all(<span class="hljs-string">'tr'</span>, bgcolor=<span class="hljs-string">'#F2F2F2'</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> navel <span class="hljs-keyword">in</span> novels:</span><br><span class="line">            a = navel.find(<span class="hljs-string">'a'</span>)</span><br><span class="line">            name = a[<span class="hljs-string">'title'</span>]</span><br><span class="line">            url = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">            <span class="hljs-keyword">yield</span> Request(url, callback=self.get_chapterurl, meta=&#123;<span class="hljs-string">'name'</span>: name, <span class="hljs-string">'url'</span>: url&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_chapterurl</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">        item = ScrapydemoItem()</span><br><span class="line">        item[<span class="hljs-string">'name'</span>] = str(response.meta[<span class="hljs-string">'name'</span>]).replace(<span class="hljs-string">'\xa0'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">        item[<span class="hljs-string">'novelurl'</span>] = response.meta[<span class="hljs-string">'url'</span>]</span><br><span class="line">        category = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'table'</span>).find(<span class="hljs-string">'a'</span>).get_text()</span><br><span class="line">        author = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'table'</span>).find_all(<span class="hljs-string">'td'</span>)[<span class="hljs-number">1</span>].get_text()</span><br><span class="line">        bash_url = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'p'</span>, class_=<span class="hljs-string">'btnlinks'</span>).find(<span class="hljs-string">'a'</span>, class_=<span class="hljs-string">'read'</span>)[<span class="hljs-string">'href'</span>]</span><br><span class="line">        name_id = str(bash_url)[<span class="hljs-number">-6</span>:<span class="hljs-number">-1</span>].replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">        item[<span class="hljs-string">'category'</span>] = str(category).replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">        item[<span class="hljs-string">'author'</span>] = str(author).replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">        item[<span class="hljs-string">'name_id'</span>] = name_id</span><br><span class="line">        <span class="hljs-keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h3 id="自定义-Pipeline"><a href="#自定义-Pipeline" class="headerlink" title="自定义 Pipeline"></a>自定义 Pipeline</h3><p>做一个自定义的MySQL的Pipeline。首先为了能好区分框架自带的Pipeline，我们把MySQL的Pipeline单独放到一个目录里面。</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy12.png" alt=""></p>
<p>pipelines.py  这个是我们写存放数据的文件</p>
<p>sql.py 看名字就知道，需要的sql语句。</p>
<p>首先是需要的 MySQL 表,<br><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-keyword">IF</span> <span class="hljs-keyword">EXISTS</span> <span class="hljs-string">`dd_name`</span>;</span><br><span class="line"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-string">`dd_name`</span> (</span><br><span class="line">  <span class="hljs-string">`id`</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="hljs-string">`xs_name`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`xs_author`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`category`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`name_id`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="hljs-keyword">KEY</span> (<span class="hljs-string">`id`</span>)</span><br><span class="line">) <span class="hljs-keyword">ENGINE</span>=<span class="hljs-keyword">InnoDB</span> AUTO_INCREMENT=<span class="hljs-number">38</span> <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">CHARSET</span>=utf8mb4;</span><br></pre></td></tr></table></figure></p>
<p>记得在 settings.py 文件中定义好 MySQL 的配置文件<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MYSQL_HOSTS = <span class="hljs-string">'127.0.0.1'</span></span><br><span class="line">MYSQL_USER = <span class="hljs-string">'root'</span></span><br><span class="line">MYSQL_PORT = <span class="hljs-string">'3306'</span></span><br><span class="line">MYSQL_PASSWORD = <span class="hljs-string">'****'</span></span><br><span class="line">MYSQL_DB = <span class="hljs-string">'xiaoshuo'</span></span><br></pre></td></tr></table></figure></p>
<p>在开始写sql.py之前，我们需要安装一个Python操作MySQL的包，来自MySQL官方的一个包：<a href="http://cdn.mysql.com//Downloads/Connector-Python/mysql-connector-python-2.1.4.zip" target="_blank" rel="noopener">点我下载</a></p>
<p>下载完成后解压出来，从 cmd 进入该目录的绝对路径，然后 python setup.py install ；即可完成安装(记得以管理员身份打开命令行)</p>
<p>sql.py<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> mysql.connector</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">from</span> ScrapyDemo <span class="hljs-keyword">import</span> settings</span><br><span class="line"></span><br><span class="line">MYSQL_USER = settings.MYSQL_USER</span><br><span class="line">MYSQL_PASSWORD = settings.MYSQL_PASSWORD</span><br><span class="line">MYSQL_HOST = settings.MYSQL_HOSTS</span><br><span class="line">MYSQL_PORT = settings.MYSQL_PORT</span><br><span class="line">MYSQL_DB = settings.MYSQL_DB</span><br><span class="line"></span><br><span class="line">cnx = mysql.connector.connect(user=MYSQL_USER, password=MYSQL_PASSWORD, host=MYSQL_HOST, database=MYSQL_DB)</span><br><span class="line">cur = cnx.cursor(buffered=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Sql</span>:</span></span><br><span class="line"><span class="hljs-meta">    @classmethod</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">insert_dd_name</span><span class="hljs-params">(cls, xs_name, xs_author, category, name_id)</span>:</span></span><br><span class="line">        sql = <span class="hljs-string">'INSERT INTO dd_name (`xs_name`,`xs_author`,`category`,``name_id) VALUES (%(xs_name)s,%(xs_author)s,,%(category)s,,%(name_id)s)'</span></span><br><span class="line">        VALUE = &#123;</span><br><span class="line">            <span class="hljs-string">'xs_name'</span>: xs_name,</span><br><span class="line">            <span class="hljs-string">'xs_author'</span>: xs_author,</span><br><span class="line">            <span class="hljs-string">'category'</span>: category,</span><br><span class="line">            <span class="hljs-string">'name_id'</span>: name_id</span><br><span class="line">        &#125;</span><br><span class="line">        cur.execute(sql, VALUE)</span><br><span class="line">        cnx.commit()</span><br><span class="line"></span><br><span class="line"><span class="hljs-meta">    @classmethod</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">select_name</span><span class="hljs-params">(cls, name_id)</span>:</span></span><br><span class="line">        sql = <span class="hljs-string">'SELECT EXISTS(SELECT 1 FROM dd_name WHERE name_id=%(name_id)s)'</span></span><br><span class="line">        value = &#123;</span><br><span class="line">            <span class="hljs-string">'name_id'</span>: name_id</span><br><span class="line">        &#125;</span><br><span class="line">        cur.execute(sql, value)</span><br><span class="line">        cnx.commit()</span><br></pre></td></tr></table></figure></p>
<p>来开始写pipeline<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> ScrapyDemo.items <span class="hljs-keyword">import</span> ScrapydemoItem</span><br><span class="line"><span class="hljs-keyword">from</span> .sql <span class="hljs-keyword">import</span> Sql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ScrapyPipeline</span><span class="hljs-params">(object)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self, item, sqider)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">if</span> isinstance(item, ScrapydemoItem):</span><br><span class="line">            name_id = item[<span class="hljs-string">'name_id'</span>]</span><br><span class="line">            ret = Sql.select_name(name_id)</span><br><span class="line">            <span class="hljs-keyword">if</span> ret[<span class="hljs-number">0</span>] == <span class="hljs-number">1</span>:</span><br><span class="line">                print(<span class="hljs-string">'已经存在了'</span>)</span><br><span class="line">                <span class="hljs-keyword">pass</span></span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                xs_name = item[<span class="hljs-string">'xs_name'</span>]</span><br><span class="line">                xs_author = item[<span class="hljs-string">'xs_author'</span>]</span><br><span class="line">                category = item[<span class="hljs-string">'category'</span>]</span><br><span class="line">                Sql.insert_dd_name(xs_name, xs_author, category, name_id)</span><br><span class="line">                print(<span class="hljs-string">'开始存小说标题'</span>)</span><br></pre></td></tr></table></figure></p>
<p>定义了一个process_item函数并有，item和spider这两个参数（<strong>请注意啊！这两玩意儿 务必！！！要加上！！千万不能少！！！！务必！！！务必！！！</strong>）</p>
<p>搞完！下面我们启用这个Pipeline在settings中作如下设置：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/setting02.png" alt=""></p>
<p>后面的 1 是优先级程度（1-1000随意设置，数值越低，组件的优先级越高）</p>
<p>下面我们开始还剩下的一些内容获取：小说章节 和章节内容</p>
<p>首先我们在 item.py 中新定义一些需要获取内容的字段：</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ScrapydemoItem</span><span class="hljs-params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="hljs-comment"># 小说名字</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 作者</span></span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 小说地址</span></span><br><span class="line">    novelurl = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 连载状态</span></span><br><span class="line">    serialstatus = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 连载字数</span></span><br><span class="line">    serialnumber = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 类别</span></span><br><span class="line">    category = scrapy.Field()</span><br><span class="line">    <span class="hljs-comment"># 编号</span></span><br><span class="line">    novel_id = scrapy.Field()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Content</span><span class="hljs-params">(scrapy.Item)</span>:</span></span><br><span class="line">    id_name = scrapy.Field()</span><br><span class="line">    chaptercontent = scrapy.Field()</span><br><span class="line">    num = scrapy.Field()</span><br><span class="line">    chapter_url = scrapy.Field()</span><br><span class="line">    chapter_name = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>继续编写Spider文件：</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_chapterurl</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">    item = ScrapydemoItem()</span><br><span class="line">    item[<span class="hljs-string">'name'</span>] = str(response.meta[<span class="hljs-string">'name'</span>]).replace(<span class="hljs-string">'\xa0'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">    item[<span class="hljs-string">'novelurl'</span>] = response.meta[<span class="hljs-string">'url'</span>]</span><br><span class="line">    category = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'table'</span>).find(<span class="hljs-string">'a'</span>).get_text()</span><br><span class="line">    author = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'table'</span>).find_all(<span class="hljs-string">'td'</span>)[<span class="hljs-number">1</span>].get_text()</span><br><span class="line">    bash_url = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'p'</span>, class_=<span class="hljs-string">'btnlinks'</span>).find(<span class="hljs-string">'a'</span>, class_=<span class="hljs-string">'read'</span>)[<span class="hljs-string">'href'</span>]</span><br><span class="line">    name_id = str(bash_url)[<span class="hljs-number">-6</span>:<span class="hljs-number">-1</span>].replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">    item[<span class="hljs-string">'category'</span>] = str(category).replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">    item[<span class="hljs-string">'author'</span>] = str(author).replace(<span class="hljs-string">'/'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">    item[<span class="hljs-string">'name_id'</span>] = name_id</span><br><span class="line">    <span class="hljs-keyword">yield</span> item</span><br><span class="line">    <span class="hljs-keyword">yield</span> Request(bash_url, callback=self.get_chapter, meta=&#123;<span class="hljs-string">'name_id'</span>: name_id&#125;)</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_chapter</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">    urls = re.findall(<span class="hljs-string">r'&lt;td class="L"&gt;&lt;a href="(.*?)"&gt;(.*?)&lt;/a&gt;&lt;/td&gt;'</span>, response.text)</span><br><span class="line">    num = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> urls:</span><br><span class="line">        num = num + <span class="hljs-number">1</span></span><br><span class="line">        chapterurl = response.url + url[<span class="hljs-number">0</span>]</span><br><span class="line">        chaptername = url[<span class="hljs-number">1</span>]</span><br><span class="line">        <span class="hljs-keyword">yield</span> Request(chapterurl, callback=self.get_chaptercontent, meta=&#123;</span><br><span class="line">            <span class="hljs-string">'num'</span>: num,</span><br><span class="line">            <span class="hljs-string">'name_id'</span>: response.meta[<span class="hljs-string">'name_id'</span>],</span><br><span class="line">            <span class="hljs-string">'chapter_url'</span>: chapterurl,</span><br><span class="line">            <span class="hljs-string">'chaptername'</span>: chaptername</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_chaptercontent</span><span class="hljs-params">(self, response)</span>:</span></span><br><span class="line">    item = Content()</span><br><span class="line">    item[<span class="hljs-string">'id_name'</span>] = response.meta[<span class="hljs-string">'name_id'</span>]</span><br><span class="line">    item[<span class="hljs-string">'num'</span>] = response.meta[<span class="hljs-string">'num'</span>]</span><br><span class="line">    item[<span class="hljs-string">'chapter_url'</span>] = response.meta[<span class="hljs-string">'chapter_url'</span>]</span><br><span class="line">    item[<span class="hljs-string">'chapter_name'</span>] = response.meta[<span class="hljs-string">'chaptername'</span>]</span><br><span class="line">    content = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'dd'</span>, id=<span class="hljs-string">'contents'</span>).get_text()</span><br><span class="line">    item[<span class="hljs-string">'content'</span>] = str(content).replace(<span class="hljs-string">'\xa0'</span>, <span class="hljs-string">''</span>)</span><br><span class="line">    <span class="hljs-keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>注意 13\14 行，这个地方返回item是不能用return的哦！用了就结束了，程序就不会继续下去了，得用 yield</p>
<p>下面我们来写存储这部分spider的Pipeline：</p>
<p>数据表：<br><figure class="highlight sql hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-keyword">IF</span> <span class="hljs-keyword">EXISTS</span> <span class="hljs-string">`dd_chaptername`</span>;</span><br><span class="line"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-string">`dd_chaptername`</span> (</span><br><span class="line">  <span class="hljs-string">`id`</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="hljs-string">`xs_chaptername`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`xs_content`</span> <span class="hljs-built_in">text</span>,</span><br><span class="line">  <span class="hljs-string">`id_name`</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`num_id`</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  <span class="hljs-string">`url`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">255</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="hljs-keyword">KEY</span> (<span class="hljs-string">`id`</span>)</span><br><span class="line">) <span class="hljs-keyword">ENGINE</span>=<span class="hljs-keyword">InnoDB</span> AUTO_INCREMENT=<span class="hljs-number">2726</span> <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">CHARSET</span>=gb18030;</span><br><span class="line"><span class="hljs-keyword">SET</span> FOREIGN_KEY_CHECKS=<span class="hljs-number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy13.png" alt=""><br><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy14.png" alt=""></p>
<p>下面是Pipeline：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/scrapy21.png" alt=""></p>
<p>有小伙伴注意，这儿比上面一个Pipeline少一个判断，因为我把判断移动到Spider中去了，这样就可以减少一次Request，减轻服务器压力。</p>
<p>改变后的Spider长这样：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/12/Scrapy16.png" alt=""></p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-09-01T16:14:49.000Z">
                    2017-09-02</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 分钟 读完 (大约 1448 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/09/02/妹子图爬虫第四弹/">
                妹子图爬虫第四弹</a>
            
        </h1>
        <div class="content">
            <h1 id="多线程多进程爬虫"><a href="#多线程多进程爬虫" class="headerlink" title="多线程多进程爬虫"></a>多线程多进程爬虫</h1><p>之前我们的程序都可以用，但是速度太慢了，因为我们只用了一个线程一个进程来进行爬虫，大部分时间都在等待，效率太低。所以接下来我们要加快我们的爬虫效率。</p>
<p>同上篇，我们用数据库的方式来解决线程以及进程间的通信问题。</p>
<p>要爬取的 url 总共有三种状态：</p>
<ul>
<li>OUTSTANDING(初始状态)</li>
<li>PROCESSING(正在下载状态)</li>
<li>COMPLETE(下载完成状态)</li>
</ul>
<p>当一个所有初始的URL状态都为outstanding；当开始爬取的时候状态改为：processing；爬取完成状态改为：complete；失败的URL重置状态为：outstanding。为了能够处理URL进程被终止的情况、我们设置一个计时参数，当超过这个值时；我们则将状态重置为outstanding。下面是代码实现：</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime, timedelta</span><br><span class="line"><span class="hljs-keyword">from</span> pymongo <span class="hljs-keyword">import</span> MongoClient, errors</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MogoQueue</span><span class="hljs-params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    OUTSTANDING = <span class="hljs-number">1</span> <span class="hljs-comment">##初始状态</span></span><br><span class="line">    PROCESSING = <span class="hljs-number">2</span> <span class="hljs-comment">##正在下载状态</span></span><br><span class="line">    COMPLETE = <span class="hljs-number">3</span> <span class="hljs-comment">##下载完成状态</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, db, collection, timeout=<span class="hljs-number">300</span>)</span>:</span><span class="hljs-comment">##初始mongodb连接</span></span><br><span class="line">        self.client = MongoClient()</span><br><span class="line">        self.Client = self.client[db]</span><br><span class="line">        self.db = self.Client[collection]</span><br><span class="line">        self.timeout = timeout</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__bool__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        这个函数，我的理解是如果下面的表达为真，则整个类为真</span></span><br><span class="line"><span class="hljs-string">        至于有什么用，后面我会注明的（如果我的理解有误，请指点出来谢谢，我也是Python新手）</span></span><br><span class="line"><span class="hljs-string">        $ne的意思是不匹配</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        record = self.db.find_one(</span><br><span class="line">            &#123;<span class="hljs-string">'status'</span>: &#123;<span class="hljs-string">'$ne'</span>: self.COMPLETE&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-keyword">True</span> <span class="hljs-keyword">if</span> record <span class="hljs-keyword">else</span> <span class="hljs-keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">push</span><span class="hljs-params">(self, url, title)</span>:</span> <span class="hljs-comment">##这个函数用来添加新的URL进队列</span></span><br><span class="line">        <span class="hljs-keyword">try</span>:</span><br><span class="line">            self.db.insert(&#123;<span class="hljs-string">'_id'</span>: url, <span class="hljs-string">'status'</span>: self.OUTSTANDING, <span class="hljs-string">'主题'</span>: title&#125;)</span><br><span class="line">            print(url, <span class="hljs-string">'插入队列成功'</span>)</span><br><span class="line">        <span class="hljs-keyword">except</span> errors.DuplicateKeyError <span class="hljs-keyword">as</span> e:  <span class="hljs-comment">##报错则代表已经存在于队列之中了</span></span><br><span class="line">            print(url, <span class="hljs-string">'已经存在于队列中了'</span>)</span><br><span class="line">            <span class="hljs-keyword">pass</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">push_imgurl</span><span class="hljs-params">(self, title, url)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">try</span>:</span><br><span class="line">            self.db.insert(&#123;<span class="hljs-string">'_id'</span>: title, <span class="hljs-string">'statue'</span>: self.OUTSTANDING, <span class="hljs-string">'url'</span>: url&#125;)</span><br><span class="line">            print(<span class="hljs-string">'图片地址插入成功'</span>)</span><br><span class="line">        <span class="hljs-keyword">except</span> errors.DuplicateKeyError <span class="hljs-keyword">as</span> e:</span><br><span class="line">            print(<span class="hljs-string">'地址已经存在了'</span>)</span><br><span class="line">            <span class="hljs-keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pop</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        这个函数会查询队列中的所有状态为OUTSTANDING的值，</span></span><br><span class="line"><span class="hljs-string">        更改状态，（query后面是查询）（update后面是更新）</span></span><br><span class="line"><span class="hljs-string">        并返回_id（就是我们的ＵＲＬ），MongDB好使吧，^_^</span></span><br><span class="line"><span class="hljs-string">        如果没有OUTSTANDING的值则调用repair()函数重置所有超时的状态为OUTSTANDING，</span></span><br><span class="line"><span class="hljs-string">        $set是设置的意思，和MySQL的set语法一个意思</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        record = self.db.find_and_modify(</span><br><span class="line">            query=&#123;<span class="hljs-string">'status'</span>: self.OUTSTANDING&#125;,</span><br><span class="line">            update=&#123;<span class="hljs-string">'$set'</span>: &#123;<span class="hljs-string">'status'</span>: self.PROCESSING, <span class="hljs-string">'timestamp'</span>: datetime.now()&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="hljs-keyword">if</span> record:</span><br><span class="line">            <span class="hljs-keyword">return</span> record[<span class="hljs-string">'_id'</span>]</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            self.repair()</span><br><span class="line">            <span class="hljs-keyword">raise</span> KeyError</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pop_title</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">        record = self.db.find_one(&#123;<span class="hljs-string">'_id'</span>: url&#125;)</span><br><span class="line">        <span class="hljs-keyword">return</span> record[<span class="hljs-string">'主题'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">peek</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""这个函数是取出状态为 OUTSTANDING的文档并返回_id(URL)"""</span></span><br><span class="line">        record = self.db.find_one(&#123;<span class="hljs-string">'status'</span>: self.OUTSTANDING&#125;)</span><br><span class="line">        <span class="hljs-keyword">if</span> record:</span><br><span class="line">            <span class="hljs-keyword">return</span> record[<span class="hljs-string">'_id'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">complete</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""这个函数是更新已完成的URL完成"""</span></span><br><span class="line">        self.db.update(&#123;<span class="hljs-string">'_id'</span>: url&#125;, &#123;<span class="hljs-string">'$set'</span>: &#123;<span class="hljs-string">'status'</span>: self.COMPLETE&#125;&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">repair</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""这个函数是重置状态$lt是比较"""</span></span><br><span class="line">        record = self.db.find_and_modify(</span><br><span class="line">           query=&#123;</span><br><span class="line">               <span class="hljs-string">'timestamp'</span>: &#123;<span class="hljs-string">'$lt'</span>: datetime.now() - timedelta(seconds=self.timeout)&#125;,</span><br><span class="line">               <span class="hljs-string">'status'</span>: &#123;<span class="hljs-string">'$ne'</span>: self.COMPLETE&#125;</span><br><span class="line">           &#125;,</span><br><span class="line">            update=&#123;<span class="hljs-string">'$set'</span>: &#123;<span class="hljs-string">'status'</span>: self.OUTSTANDING&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="hljs-keyword">if</span> record:</span><br><span class="line">            print(<span class="hljs-string">'重置URL状态'</span>, record[<span class="hljs-string">'_id'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">clear</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        <span class="hljs-string">"""这个函数只有第一次才调用、后续不要调用、因为这是删库啊！"""</span></span><br><span class="line">        self.db.drop()</span><br></pre></td></tr></table></figure>
<p>接下来就需要来爬取所有的链接地址来存进我们的数据库里了。</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> Download <span class="hljs-keyword">import</span> request</span><br><span class="line"><span class="hljs-keyword">from</span> mongodb_queue <span class="hljs-keyword">import</span> MogoQueue</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spider_queue = MogoQueue(<span class="hljs-string">'meinvxiezhenji'</span>, <span class="hljs-string">'crawl_queue'</span>)</span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start</span><span class="hljs-params">(url)</span>:</span></span><br><span class="line">    response = request.get(url, <span class="hljs-number">3</span>)</span><br><span class="line">    Soup = BeautifulSoup(response.text, <span class="hljs-string">'lxml'</span>)</span><br><span class="line">    all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>)</span><br><span class="line">    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">        title = a.get_text()</span><br><span class="line">        url = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">        spider_queue.push(url, title)</span><br><span class="line">    <span class="hljs-string">"""上面这个调用就是把URL写入MongoDB的队列了"""</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    start(<span class="hljs-string">'http://www.mzitu.com/all'</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-string">"""这一段儿就不解释了哦！超级简单的"""</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"><span class="hljs-keyword">import</span> time</span><br><span class="line"><span class="hljs-keyword">import</span> threading</span><br><span class="line"><span class="hljs-keyword">import</span> multiprocessing</span><br><span class="line"><span class="hljs-keyword">from</span> mongodb_queue <span class="hljs-keyword">import</span> MogoQueue</span><br><span class="line"><span class="hljs-keyword">from</span> Download <span class="hljs-keyword">import</span> request</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">SLEEP_TIME = <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mzitu_crawler</span><span class="hljs-params">(max_threads=<span class="hljs-number">10</span>)</span>:</span></span><br><span class="line">    crawl_queue = MogoQueue(<span class="hljs-string">'meinvxiezhenji'</span>, <span class="hljs-string">'crawl_queue'</span>) <span class="hljs-comment">##这个是我们获取URL的队列</span></span><br><span class="line">    <span class="hljs-comment">##img_queue = MogoQueue('meinvxiezhenji', 'img_queue')</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pageurl_crawler</span><span class="hljs-params">()</span>:</span></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:</span><br><span class="line">            <span class="hljs-keyword">try</span>:</span><br><span class="line">                url = crawl_queue.pop()</span><br><span class="line">                print(url)</span><br><span class="line">            <span class="hljs-keyword">except</span> KeyError:</span><br><span class="line">                print(<span class="hljs-string">'队列没有数据'</span>)</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                img_urls = []</span><br><span class="line">                req = request.get(url, <span class="hljs-number">3</span>).text</span><br><span class="line">                title = crawl_queue.pop_title(url)</span><br><span class="line">                mkdir(title)</span><br><span class="line">                os.chdir(<span class="hljs-string">'D:\mzitu\\'</span> + title)</span><br><span class="line">                max_span = BeautifulSoup(req, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">-2</span>].get_text()</span><br><span class="line">                <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">                    page_url = url + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">                    img_url = BeautifulSoup(request.get(page_url, <span class="hljs-number">3</span>).text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">                    img_urls.append(img_url)</span><br><span class="line">                    save(img_url)</span><br><span class="line">                crawl_queue.complete(url) <span class="hljs-comment">##设置为完成状态</span></span><br><span class="line">                <span class="hljs-comment">##img_queue.push_imgurl(title, img_urls)</span></span><br><span class="line">                <span class="hljs-comment">##print('插入数据库成功')</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="hljs-number">-9</span>:<span class="hljs-number">-4</span>]</span><br><span class="line">        print(<span class="hljs-string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = request.get(img_url, <span class="hljs-number">3</span>)</span><br><span class="line">        f = open(name + <span class="hljs-string">'.jpg'</span>, <span class="hljs-string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mkdir</span><span class="hljs-params">(path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isExists:</span><br><span class="line">            print(<span class="hljs-string">u'建了一个名字叫做'</span>, path, <span class="hljs-string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">True</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            print(<span class="hljs-string">u'名字叫做'</span>, path, <span class="hljs-string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span></span><br><span class="line"></span><br><span class="line">    threads = []</span><br><span class="line">    <span class="hljs-keyword">while</span> threads <span class="hljs-keyword">or</span> crawl_queue:</span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        这儿crawl_queue用上了，就是我们__bool__函数的作用，为真则代表我们MongoDB队列里面还有数据</span></span><br><span class="line"><span class="hljs-string">        threads 或者 crawl_queue为真都代表我们还没下载完成，程序就会继续执行</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        <span class="hljs-keyword">for</span> thread <span class="hljs-keyword">in</span> threads:</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> thread.is_alive(): <span class="hljs-comment">##is_alive是判断是否为空,不是空则在队列中删掉</span></span><br><span class="line">                threads.remove(thread)</span><br><span class="line">        <span class="hljs-keyword">while</span> len(threads) &lt; max_threads <span class="hljs-keyword">or</span> crawl_queue.peek(): <span class="hljs-comment">##线程池中的线程少于max_threads 或者 crawl_qeue时</span></span><br><span class="line">            thread = threading.Thread(target=pageurl_crawler) <span class="hljs-comment">##创建线程</span></span><br><span class="line">            thread.setDaemon(<span class="hljs-keyword">True</span>) <span class="hljs-comment">##设置守护线程</span></span><br><span class="line">            thread.start() <span class="hljs-comment">##启动线程</span></span><br><span class="line">            threads.append(thread) <span class="hljs-comment">##添加进线程队列</span></span><br><span class="line">        time.sleep(SLEEP_TIME)</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_crawler</span><span class="hljs-params">()</span>:</span></span><br><span class="line">    process = []</span><br><span class="line">    num_cpus = multiprocessing.cpu_count()</span><br><span class="line">    print(<span class="hljs-string">'将会启动进程数为：'</span>, num_cpus)</span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_cpus):</span><br><span class="line">        p = multiprocessing.Process(target=mzitu_crawler) <span class="hljs-comment">##创建进程</span></span><br><span class="line">        p.start() <span class="hljs-comment">##启动进程</span></span><br><span class="line">        process.append(p) <span class="hljs-comment">##添加进进程队列</span></span><br><span class="line">    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> process:</span><br><span class="line">        p.join() <span class="hljs-comment">##等待进程队列里面的进程结束</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    process_crawler()</span><br></pre></td></tr></table></figure>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-image">
        <a href="/2017/08/29/妹子图爬虫第三弹/" class="image is-7by1">
        <img class="thumbnail" src="http://o797mwhn1.bkt.clouddn.com/han.jpg" alt="妹子图爬虫第三弹">
        </a>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-08-29T14:42:49.000Z">
                    2017-08-29</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    12 分钟 读完 (大约 1726 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/08/29/妹子图爬虫第三弹/">
                妹子图爬虫第三弹</a>
            
        </h1>
        <div class="content">
            <p>前面两篇的教程教大家写了一个基础的爬虫程序，但是有问题啊，每次开始时都要重新下载，很难受。所以我们要解决这个问题，关键点在于要把我们爬过的页面记录下来，避免重复。在这里，原文作者使用 <a href="https://www.mongodb.com/" target="_blank" rel="noopener">MongoDB</a> (一个基于分布式文件存储的非关系型数据库) 来存储数据的，我也是不怎么明白什么是 非关系型数据库…不过这里有<a href="http://www.runoob.com/mongodb/mongodb-tutorial.html" target="_blank" rel="noopener">教程</a>，大家可以看看。</p>
<p>首先是 MongoDB 的安装。例如把它安在 C 盘下 <code>D:\software\MongoDB\Server</code> ，之后需要创建两个目录：</p>
<p>D:\software\MongoDB\mongod.log(文件)             存储日志</p>
<p>D:\software\MongoDB\db    存储数据</p>
<p>然后以管理员身份打开命令行窗口，执行以下命令</p>
<p><code>&quot;D:\software\MongoDB\Server\3.4\bin\mongod.exe&quot; --config &quot;D:\software\MongoDB\Server\3.4\mongod.cfg&quot; --install</code></p>
<p>如图安装成功</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/11/%E5%AE%89%E8%A3%85%E6%9C%8D%E5%8A%A1.gif" alt=""></p>
<p>用命令 <code>net start MongoDB</code> 来启动服务。</p>
<p>对了，还需要安装 MongoDB 的 python 模块 <code>pip install PyMongo</code></p>
<p>现在我们在上一篇博文完成的代码中导入模块：</p>
<p><code>from pymongo import MongoClient</code></p>
<p>代码改造第一步，在类 mzitu 里添加一个函数：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">    client = MongoClient() <span class="hljs-comment">##与MongDB建立连接（这是默认连接本地MongDB数据库）</span></span><br><span class="line">    db = client[<span class="hljs-string">'meinvxiezhenji'</span>] <span class="hljs-comment">## 选择一个数据库</span></span><br><span class="line">    self.meizitu_collection = db[<span class="hljs-string">'meizitu'</span>] <span class="hljs-comment">##在meizixiezhenji这个数据库中，选择一个集合</span></span><br><span class="line">    self.title = <span class="hljs-string">''</span> <span class="hljs-comment">##用来保存页面主题</span></span><br><span class="line">    self.url = <span class="hljs-string">''</span> <span class="hljs-comment">##用来保存页面地址</span></span><br><span class="line">    self.img_urls = [] <span class="hljs-comment">##初始化一个 列表 用来保存图片地址</span></span><br></pre></td></tr></table></figure></p>
<p>之后要改一下 all_url 函数：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">all_url</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">    html = down.get(url, <span class="hljs-number">3</span>) </span><br><span class="line">    all_a = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>)</span><br><span class="line">    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">        title = a.get_text()</span><br><span class="line">        self.title = title <span class="hljs-comment">##将主题保存到self.title中</span></span><br><span class="line">        print(<span class="hljs-string">u'开始保存：'</span>, title)</span><br><span class="line">        path = str(title).replace(<span class="hljs-string">"?"</span>, <span class="hljs-string">'_'</span>)</span><br><span class="line">        self.mkdir(path)</span><br><span class="line">        os.chdir(<span class="hljs-string">"D:\mzitu\\"</span>+path)</span><br><span class="line">        href = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">        self.url = href <span class="hljs-comment">##将页面地址保存到self.url中</span></span><br><span class="line">        <span class="hljs-keyword">if</span> self.meizitu_collection.find_one(&#123;<span class="hljs-string">'主题页面'</span>: href&#125;):  <span class="hljs-comment">##判断这个主题是否已经在数据库中、不在就运行else下的内容，在则忽略。</span></span><br><span class="line">            print(<span class="hljs-string">u'这个页面已经爬取过了'</span>)</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            self.html(href)</span><br></pre></td></tr></table></figure></p>
<p>接着改 html 函数：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">html</span><span class="hljs-params">(self, href)</span>:</span></span><br><span class="line">    html = down.get(href, <span class="hljs-number">3</span>)</span><br><span class="line">    max_span = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">10</span>].get_text()</span><br><span class="line">    page_num = <span class="hljs-number">0</span>  <span class="hljs-comment">##这个当作计数器用 （用来判断图片是否下载完毕）</span></span><br><span class="line">    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">        page_num = page_num + <span class="hljs-number">1</span> <span class="hljs-comment">##每for循环一次就+1  （当page_num等于max_span的时候，就证明我们的在下载最后一张图片了）</span></span><br><span class="line">        page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">        self.img(page_url, max_span, page_num)  <span class="hljs-comment">##把上面我们我们需要的两个变量，传递给下一个函数。</span></span><br></pre></td></tr></table></figure></p>
<p>改 img 函数…<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img</span><span class="hljs-params">(self, page_url, max_span, page_num)</span>:</span> <span class="hljs-comment">##添加上面传递的参数</span></span><br><span class="line">    img_html = down.get(page_url, <span class="hljs-number">3</span>)</span><br><span class="line">    img_url = BeautifulSoup(img_html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">    self.img_urls.append(img_url) <span class="hljs-comment">##每一次 for page in range(1, int(max_span) + 1)获取到的图片地址都会添加到 img_urls这个初始化的列表</span></span><br><span class="line">    <span class="hljs-keyword">if</span> int(max_span) == page_num: <span class="hljs-comment">##我们传递下来的两个参数用上了 当max_span和Page_num相等时，就是最后一张图片了，最后一次下载图片并保存到数据库中。</span></span><br><span class="line">        self.save(img_url)</span><br><span class="line">        post = &#123;  <span class="hljs-comment">##这是构造一个字典，里面有啥都是中文，很好理解吧！</span></span><br><span class="line">            <span class="hljs-string">'标题'</span>: self.title,</span><br><span class="line">            <span class="hljs-string">'主题页面'</span>: self.url,</span><br><span class="line">            <span class="hljs-string">'图片地址'</span>: self.img_urls,</span><br><span class="line">            <span class="hljs-string">'获取时间'</span>: datetime.datetime.now()</span><br><span class="line">        &#125;</span><br><span class="line">        self.meizitu_collection.save(post) <span class="hljs-comment">##将post中的内容写入数据库。</span></span><br><span class="line">        print(<span class="hljs-string">u'插入数据库成功'</span>)</span><br><span class="line">    <span class="hljs-keyword">else</span>:  <span class="hljs-comment">##max_span 不等于 page_num执行这下面</span></span><br><span class="line">        self.save(img_url)</span><br></pre></td></tr></table></figure></p>
<p>完整的代码在此<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"><span class="hljs-keyword">from</span> Download <span class="hljs-keyword">import</span> down <span class="hljs-comment">##导入模块变了一下</span></span><br><span class="line"><span class="hljs-keyword">from</span> pymongo <span class="hljs-keyword">import</span> MongoClient</span><br><span class="line"><span class="hljs-keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">mzitu</span><span class="hljs-params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        client = MongoClient() <span class="hljs-comment">##与MongDB建立连接（这是默认连接本地MongDB数据库）</span></span><br><span class="line">        db = client[<span class="hljs-string">'meinvxiezhenji'</span>] <span class="hljs-comment">## 选择一个数据库</span></span><br><span class="line">        self.meizitu_collection = db[<span class="hljs-string">'meizitu'</span>] <span class="hljs-comment">##在meizixiezhenji这个数据库中，选择一个集合</span></span><br><span class="line">        self.title = <span class="hljs-string">''</span> <span class="hljs-comment">##用来保存页面主题</span></span><br><span class="line">        self.url = <span class="hljs-string">''</span> <span class="hljs-comment">##用来保存页面地址</span></span><br><span class="line">        self.img_urls = [] <span class="hljs-comment">##初始化一个 列表  用来保存图片地址</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">all_url</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">        html = down.get(url, <span class="hljs-number">3</span>)</span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            self.title = title <span class="hljs-comment">##将主题保存到self.title中</span></span><br><span class="line">            print(<span class="hljs-string">u'开始保存：'</span>, title)</span><br><span class="line">            path = str(title).replace(<span class="hljs-string">"?"</span>, <span class="hljs-string">'_'</span>)</span><br><span class="line">            self.mkdir(path)</span><br><span class="line">            os.chdir(<span class="hljs-string">"D:\mzitu\\"</span>+path)</span><br><span class="line">            href = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">            self.url = href <span class="hljs-comment">##将页面地址保存到self.url中</span></span><br><span class="line">            <span class="hljs-keyword">if</span> self.meizitu_collection.find_one(&#123;<span class="hljs-string">'主题页面'</span>: href&#125;):  <span class="hljs-comment">##判断这个主题是否已经在数据库中、不在就运行else下的内容，在则忽略。</span></span><br><span class="line">                print(<span class="hljs-string">u'这个页面已经爬取过了'</span>)</span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                self.html(href)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">html</span><span class="hljs-params">(self, href)</span>:</span></span><br><span class="line">        html = down.get(href, <span class="hljs-number">3</span>)</span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">10</span>].get_text()</span><br><span class="line">        page_num = <span class="hljs-number">0</span>  <span class="hljs-comment">##这个当作计数器用 （用来判断图片是否下载完毕）</span></span><br><span class="line">        <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">            page_num = page_num + <span class="hljs-number">1</span> <span class="hljs-comment">##每for循环一次就+1  （当page_num等于max_span的时候，就证明我们的在下载最后一张图片了）</span></span><br><span class="line">            page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url, max_span, page_num)  <span class="hljs-comment">##把上面我们我们需要的两个变量，传递给下一个函数。</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img</span><span class="hljs-params">(self, page_url, max_span, page_num)</span>:</span> <span class="hljs-comment">##添加上面传递的参数</span></span><br><span class="line">        img_html = down.get(page_url, <span class="hljs-number">3</span>)</span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">        self.img_urls.append(img_url) <span class="hljs-comment">##每一次 for page in range(1, int(max_span) + 1)获取到的图片地址都会添加到 img_urls这个初始化的列表</span></span><br><span class="line">        <span class="hljs-keyword">if</span> int(max_span) == page_num: <span class="hljs-comment">##我们传递下来的两个参数用上了 当max_span和Page_num相等时，就是最后一张图片了，最后一次下载图片并保存到数据库中。</span></span><br><span class="line">            self.save(img_url)</span><br><span class="line">            post = &#123;  <span class="hljs-comment">##这是构造一个字典，里面有啥都是中文，很好理解吧！</span></span><br><span class="line">                <span class="hljs-string">'标题'</span>: self.title,</span><br><span class="line">                <span class="hljs-string">'主题页面'</span>: self.url,</span><br><span class="line">                <span class="hljs-string">'图片地址'</span>: self.img_urls,</span><br><span class="line">                <span class="hljs-string">'获取时间'</span>: datetime.datetime.now()</span><br><span class="line">            &#125;</span><br><span class="line">            self.meizitu_collection.save(post) <span class="hljs-comment">##将post中的内容写入数据库。</span></span><br><span class="line">            print(<span class="hljs-string">u'插入数据库成功'</span>)</span><br><span class="line">        <span class="hljs-keyword">else</span>:  <span class="hljs-comment">##max_span 不等于 page_num执行这下面</span></span><br><span class="line">            self.save(img_url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(self, img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="hljs-number">-9</span>:<span class="hljs-number">-4</span>]</span><br><span class="line">        print(<span class="hljs-string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = down.get(img_url, <span class="hljs-number">3</span>)</span><br><span class="line">        f = open(name + <span class="hljs-string">'.jpg'</span>, <span class="hljs-string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mkdir</span><span class="hljs-params">(self, path)</span>:</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isExists:</span><br><span class="line">            print(<span class="hljs-string">u'建了一个名字叫做'</span>, path, <span class="hljs-string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">True</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            print(<span class="hljs-string">u'名字叫做'</span>, path, <span class="hljs-string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="hljs-comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="hljs-string">'http://www.mzitu.com/all'</span>) <span class="hljs-comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre></td></tr></table></figure></p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-08-28T15:05:39.000Z">
                    2017-08-28</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    9 分钟 读完 (大约 1415 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/08/28/妹子图爬虫第二弹/">
                妹子图爬虫第二弹</a>
            
        </h1>
        <div class="content">
            <p>上一篇文章中教大家去爬取妹子图，但是会出现很多问题，比如爬着爬着发现一直在报错，重新再来的话又得从第一张图开始下，太麻烦。通常是因为网站的反爬虫策略起了作用。</p>
<p>一般反爬虫策略有以下几种：</p>
<ul>
<li>后台对访问进行统计，如果单个IP访问超过阈值，予以封锁。</li>
<li>后台对访问进行统计，如果单个session访问超过阈值，予以封锁。</li>
<li>后台对访问进行统计，如果单个userAgent访问超过阈值，予以封锁。</li>
<li>以上的组合。</li>
</ul>
<p>针对上面的第一二条，来写个基本的下载模块。原理就是利用的不同的 User-Ahent 和 IP 来进行爬虫。</p>
<p>首先随便就可以在网上找到很多 User-Agent 。</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;,</span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;</span><br></pre></td></tr></table></figure>
<p>新建个下载的类然后改下代码</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">import</span> re</span><br><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">download</span><span class="hljs-params">(object)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">        UA = random.choice(self.user_agent_list) <span class="hljs-comment">##从self.user_agent_list中随机取出一个字符串（聪明的小哥儿一定发现了这是完整的User-Agent中：后面的一半段）</span></span><br><span class="line">        headers = &#123;<span class="hljs-string">'User-Agent'</span>: UA&#125;  <span class="hljs-comment">##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span></span><br><span class="line">        response = requests.get(url, headers=headers) <span class="hljs-comment">##这样服务器就会以为我们是真的浏览器了</span></span><br><span class="line">        <span class="hljs-keyword">return</span> response</span><br></pre></td></tr></table></figure>
<p>下一步就是要找一些能用的 IP 了。网上有一些 IP 代理的网站，通常会发一些免费的代理 IP，比如 <strong><a href="http://haoip.cc/tiqu.htm" target="_blank" rel="noopener">http://haoip.cc/tiqu.htm</a></strong> 。</p>
<p>下面的代码可以爬下来这些 IP。</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">iplist = [] <span class="hljs-comment">##初始化一个list用来存放我们获取到的IP</span></span><br><span class="line">html = requests.get(<span class="hljs-string">"http://haoip.cc/tiqu.htm"</span>)<span class="hljs-comment">##不解释咯</span></span><br><span class="line">iplistn = re.findall(<span class="hljs-string">r'r/&gt;(.*?)&lt;b'</span>, html.text, re.S) <span class="hljs-comment">##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span></span><br><span class="line"><span class="hljs-keyword">for</span> ip <span class="hljs-keyword">in</span> iplistn:</span><br><span class="line">    i = re.sub(<span class="hljs-string">'\n'</span>, <span class="hljs-string">''</span>, ip)<span class="hljs-comment">##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span></span><br><span class="line">    iplist.append(i.strip()) <span class="hljs-comment">##添加到我们上面初始化的list里面, i.strip()的意思是去掉字符串的空格哦！！</span></span><br><span class="line">    print(i.strip())</span><br><span class="line">print(iplist)</span><br></pre></td></tr></table></figure>
<p>然后一顿操作</p>
<p>Download.py<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">import</span> re</span><br><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">download</span><span class="hljs-params">()</span>:</span></span><br><span class="line"> </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line"> </span><br><span class="line">        self.iplist = []  <span class="hljs-comment">##初始化一个list用来存放我们获取到的IP</span></span><br><span class="line">        html = requests.get(<span class="hljs-string">"http://haoip.cc/tiqu.htm"</span>)  <span class="hljs-comment">##不解释咯</span></span><br><span class="line">        iplistn = re.findall(<span class="hljs-string">r'r/&gt;(.*?)&lt;b'</span>, html.text, re.S)  <span class="hljs-comment">##表示从html.text中获取所有r/&gt;&lt;b中的内容，re.S的意思是包括匹配包括换行符，findall返回的是个list哦！</span></span><br><span class="line">        <span class="hljs-keyword">for</span> ip <span class="hljs-keyword">in</span> iplistn:</span><br><span class="line">            i = re.sub(<span class="hljs-string">'\n'</span>, <span class="hljs-string">''</span>, ip)  <span class="hljs-comment">##re.sub 是re模块替换的方法，这儿表示将\n替换为空</span></span><br><span class="line">            self.iplist.append(i.strip())  <span class="hljs-comment">##添加到我们上面初始化的list里面</span></span><br><span class="line"> </span><br><span class="line">        self.user_agent_list = [</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,</span><br><span class="line">            <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">        ]</span><br><span class="line"> </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span><span class="hljs-params">(self, url, timeout, proxy=None, num_retries=<span class="hljs-number">6</span>)</span>:</span> <span class="hljs-comment">##给函数一个默认参数proxy为空</span></span><br><span class="line">        UA = random.choice(self.user_agent_list) <span class="hljs-comment">##从self.user_agent_list中随机取出一个字符串</span></span><br><span class="line">        headers = &#123;<span class="hljs-string">'User-Agent'</span>: UA&#125;  <span class="hljs-comment">##构造成一个完整的User-Agent （UA代表的是上面随机取出来的字符串哦）</span></span><br><span class="line"> </span><br><span class="line">        <span class="hljs-keyword">if</span> proxy == <span class="hljs-keyword">None</span>: <span class="hljs-comment">##当代理为空时，不使用代理获取response（别忘了response啥哦！之前说过了！！）</span></span><br><span class="line">            <span class="hljs-keyword">try</span>:</span><br><span class="line">                <span class="hljs-keyword">return</span> requests.get(url, headers=headers, timeout=timeout)<span class="hljs-comment">##这样服务器就会以为我们是真的浏览器了</span></span><br><span class="line">            <span class="hljs-keyword">except</span>:<span class="hljs-comment">##如过上面的代码执行报错则执行下面的代码</span></span><br><span class="line"> </span><br><span class="line">                <span class="hljs-keyword">if</span> num_retries &gt; <span class="hljs-number">0</span>: <span class="hljs-comment">##num_retries是我们限定的重试次数</span></span><br><span class="line">                    time.sleep(<span class="hljs-number">10</span>) <span class="hljs-comment">##延迟十秒</span></span><br><span class="line">                    print(<span class="hljs-string">u'获取网页出错，10S后将获取倒数第：'</span>, num_retries, <span class="hljs-string">u'次'</span>)</span><br><span class="line">                    <span class="hljs-keyword">return</span> self.get(url, timeout, num_retries<span class="hljs-number">-1</span>)  <span class="hljs-comment">##调用自身 并将次数减1</span></span><br><span class="line">                <span class="hljs-keyword">else</span>:</span><br><span class="line">                    print(<span class="hljs-string">u'开始使用代理'</span>)</span><br><span class="line">                    time.sleep(<span class="hljs-number">10</span>)</span><br><span class="line">                    IP = <span class="hljs-string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="hljs-comment">##下面有解释哦</span></span><br><span class="line">                    proxy = &#123;<span class="hljs-string">'http'</span>: IP&#125;</span><br><span class="line">                    <span class="hljs-keyword">return</span> self.get(url, timeout, proxy,) <span class="hljs-comment">##代理不为空的时候</span></span><br><span class="line"> </span><br><span class="line">        <span class="hljs-keyword">else</span>: <span class="hljs-comment">##当代理不为空</span></span><br><span class="line">            <span class="hljs-keyword">try</span>:</span><br><span class="line">                IP = <span class="hljs-string">''</span>.join(str(random.choice(self.iplist)).strip()) <span class="hljs-comment">##将从self.iplist中获取的字符串处理成我们需要的格式（处理了些什么自己看哦，这是基础呢）</span></span><br><span class="line">                proxy = &#123;<span class="hljs-string">'http'</span>: IP&#125; <span class="hljs-comment">##构造成一个代理</span></span><br><span class="line">                <span class="hljs-keyword">return</span> requests.get(url, headers=headers, proxies=proxy, timeout=timeout) <span class="hljs-comment">##使用代理获取response</span></span><br><span class="line">            <span class="hljs-keyword">except</span>:</span><br><span class="line"> </span><br><span class="line">                <span class="hljs-keyword">if</span> num_retries &gt; <span class="hljs-number">0</span>:</span><br><span class="line">                    time.sleep(<span class="hljs-number">10</span>)</span><br><span class="line">                    IP = <span class="hljs-string">''</span>.join(str(random.choice(self.iplist)).strip())</span><br><span class="line">                    proxy = &#123;<span class="hljs-string">'http'</span>: IP&#125;</span><br><span class="line">                    print(<span class="hljs-string">u'正在更换代理，10S后将重新获取倒数第'</span>, num_retries, <span class="hljs-string">u'次'</span>)</span><br><span class="line">                    print(<span class="hljs-string">u'当前代理是：'</span>, proxy)</span><br><span class="line">                    <span class="hljs-keyword">return</span> self.get(url, timeout, proxy, num_retries - <span class="hljs-number">1</span>)</span><br><span class="line">                <span class="hljs-keyword">else</span>:</span><br><span class="line">                    print(<span class="hljs-string">u'代理也不好使了！取消代理'</span>)</span><br><span class="line">                    <span class="hljs-keyword">return</span> self.get(url, <span class="hljs-number">3</span>)</span><br><span class="line"> </span><br><span class="line">request = download()</span><br></pre></td></tr></table></figure></p>
<p>再改下 mzitu.py 中的代码</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"><span class="hljs-keyword">from</span> Download <span class="hljs-keyword">import</span> request <span class="hljs-comment">##导入模块变了一下</span></span><br><span class="line"><span class="hljs-keyword">from</span> pymongo <span class="hljs-keyword">import</span> MongoClient</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">mzitu</span><span class="hljs-params">()</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">all_url</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line"></span><br><span class="line">        html = request.get(url, <span class="hljs-number">3</span>) </span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            print(<span class="hljs-string">u'开始保存：'</span>, title)</span><br><span class="line">            path = str(title).replace(<span class="hljs-string">"?"</span>, <span class="hljs-string">'_'</span>)</span><br><span class="line">            self.mkdir(path)</span><br><span class="line">            os.chdir(<span class="hljs-string">"D:\mzitu\\"</span>+path)</span><br><span class="line">            href = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">            self.html(href)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">html</span><span class="hljs-params">(self, href)</span>:</span></span><br><span class="line">        html = request.get(href, <span class="hljs-number">3</span>)</span><br><span class="line">        max_span = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">10</span>].get_text()</span><br><span class="line">        <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">            page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img</span><span class="hljs-params">(self, page_url)</span>:</span></span><br><span class="line">        img_html = request.get(page_url, <span class="hljs-number">3</span>) </span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">        self.save(img_url)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(self, img_url)</span>:</span></span><br><span class="line">        name = img_url[<span class="hljs-number">-9</span>:<span class="hljs-number">-4</span>]</span><br><span class="line">        print(<span class="hljs-string">u'开始保存：'</span>, img_url)</span><br><span class="line">        img = request.get(img_url, <span class="hljs-number">3</span>) </span><br><span class="line">        f = open(name + <span class="hljs-string">'.jpg'</span>, <span class="hljs-string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mkdir</span><span class="hljs-params">(self, path)</span>:</span> </span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isExists:</span><br><span class="line">            print(<span class="hljs-string">u'建了一个名字叫做'</span>, path, <span class="hljs-string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">True</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            print(<span class="hljs-string">u'名字叫做'</span>, path, <span class="hljs-string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="hljs-comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="hljs-string">'http://www.mzitu.com/all'</span>) <span class="hljs-comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre></td></tr></table></figure>
<p><strong>注意：两个 py 文件要放在一个文件夹下，文件夹中还要新建一个叫 <strong>init</strong>.py 的空文件</strong></p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-08-28T14:12:25.000Z">
                    2017-08-28</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/爬虫/">爬虫</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    22 分钟 读完 (大约 3226 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/08/28/妹子图爬虫第一弹/">
                妹子图爬虫第一弹</a>
            
        </h1>
        <div class="content">
            <p><strong>本教程是根据 <a href="http://cuiqingcai.com/3179.html" target="_blank" rel="noopener">小白爬虫第一弹之抓取妹子图</a> 编写</strong></p>
<h1 id="杂"><a href="#杂" class="headerlink" title="杂"></a>杂</h1><p>首先上边卧槽哥写的这个爬虫教程看过好几遍了，自己也跟着写了两三次了。开始觉得 哈，这么厉害，python 爬虫原来这么简单，因垂丝汀。但是后来发现“自己跟着写过”这个过程，其实能记住的知识很少。加上最近自己一直很迷茫，不知道该往哪个方面发展，不知道该学什么，在 python 和 java 中纠结，在 爬虫 还是 服务器 中纠结。前两周还看了两周的 <a href="http://eyehere.net/2011/python-pygame-novice-professional-index/" target="_blank" rel="noopener">用Python和Pygame写游戏</a>，慢慢学着发现，教程是基于 python2 的，而我的电脑安装的环境是 python3.5 的，很多教程上需要的包 和一些方法都不能用，而且教程已经是六年前的了，不能说已经被放弃了吧，还是有些过时，python 执行效率又不高，只能写一些小游戏。所以说还是从基础开始，往深里学，用心学习。</p>
<p>想起了之前看到的一张图</p>
<p><img src="http://o797mwhn1.bkt.clouddn.com/QQ%E5%9B%BE%E7%89%8720170828202514.png" alt=""></p>
<p>自己听过的不如读过的，读过的不如讨论过的，讨论过的不如教给其他人的。所以我决定以后要把自己学过的知识，自己写出来，写在博客里。这样自己也印象比较深刻，要是我写的博文能帮到其他人那就更好了。</p>
<h1 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h1><p>首先，我承认，我看上面所说的那个教程的时候，完全是被要爬取的网站吸引了。毕竟xx是学习第一动力(/滑稽)。</p>
<p>下面先来看看完成这篇教程所需要的基础环境</p>
<ul>
<li>Python。本教程是基于 python3 来写。windows用户可以安装 <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">anaconda</a>,这是一个Python的科学计算发行版本，作者打包好多好多的包。</li>
<li>Requests。网络请求包。</li>
<li>beautifulsoup。可以从 html 文件中提取数据，非常方便，不用再搞那些恶心的正则表达式了。</li>
<li>LXML。一个HTML解析包 用于辅助beautifulsoup解析网页。</li>
</ul>
<p>安装这些模块的话可以通过命令行来安装<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda install requests</span><br><span class="line">conda install beautifulsoup4</span><br><span class="line">conda install lxml</span><br><span class="line">或者</span><br><span class="line">pip install requests</span><br><span class="line">pip install beautifulsoup4</span><br><span class="line">pip install lxml</span><br></pre></td></tr></table></figure></p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>重点来了！！我们要爬的网站是 <a href="http://www.mzitu.com/all/" target="_blank" rel="noopener">妹子图</a> , 开不开心，激不激动。</p>
<p>网站的 <code>http://www.mzitu.com/all</code> 页面有整个网站全部的数据，贼良心。我们就在这个页面开启我们的爬虫之旅。Just do it！</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125; <span class="hljs-comment">## 浏览器请求头</span></span><br><span class="line"></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span></span><br><span class="line"></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)<span class="hljs-comment">##使用 requests 来获取 all_url 的内容，并且把 headers 作为请求头</span></span><br><span class="line"></span><br><span class="line">print(start_html.text)  <span class="hljs-comment">##把爬取到的内容打印出来  !!!记住网页内容是 .text</span></span><br></pre></td></tr></table></figure>
<p>执行上面的代码会在控制台输出 all_url 页面的 html 源码。</p>
<p>目前只是爬到了网页的 html 源文件，但是我们是要爬图的啊！！！我们要美女图啊！！！爬虫才刚开始，慢慢来。</p>
<p>在 chrome 中打开 <code>http://www.mzitu.com/all</code>，按下 F12 调出开发者调试工具。</p>
<p>如图：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161024205256-1024x559.png" alt=""></p>
<p>点击调试窗口左上角的那个小箭头，这样浏览器会根据你鼠标选中的视图显示相应的 html 代码。</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161025224053-1024x615.png" alt=""></p>
<p>如图，所有的图片链接地址都在 <code>&lt;li&gt;...&lt;/li&gt;</code> 里</p>
<p>随便点开一个 <code>&lt;li&gt;</code> 标签</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161025224601-1024x604.png" alt=""></p>
<p>会发现图片页面的地址在<code>&lt;a&gt;</code>标签的href属性中、主题在<code>&lt;a&gt;</code>标签中。所以我们只要爬取所有<code>&lt;li&gt;</code>标签里的内容就能爬取我们想要的地址了。</p>
<p>但是页面里还有好多不符合要求的<code>&lt;li&gt;</code>标签，所以要筛选一下。通过观察发现，所有的文章主题地址都在 <code>&lt;div class=&#39;all&#39;&gt;...&lt;/div&gt;</code> 标签里。就是 <code>&lt;div class=&#39;all&#39;&gt;</code> 里的 <code>&lt;a&gt;</code> </p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125; <span class="hljs-comment">## 浏览器请求头</span></span><br><span class="line"></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span></span><br><span class="line"></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)<span class="hljs-comment">##使用 requests 来获取 all_url 的内容，并且把 headers 作为请求头</span></span><br><span class="line"></span><br><span class="line">all_soup = BeutifulSoup(start_html.text,<span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span></span><br><span class="line"></span><br><span class="line">all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>) <span class="hljs-comment">##意思是先查找 class为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span></span><br><span class="line"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">    print(a)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161028150438.png" alt=""></p>
<p>然后就该提取我们想要的内容了</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125; <span class="hljs-comment">## 浏览器请求头</span></span><br><span class="line"></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span></span><br><span class="line"></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)<span class="hljs-comment">##使用 requests 来获取 all_url 的内容，并且把 headers 作为请求头</span></span><br><span class="line"></span><br><span class="line">all_soup = BeutifulSoup(start_html.text,<span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span></span><br><span class="line"></span><br><span class="line">all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>) <span class="hljs-comment">##意思是先查找 class为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span></span><br><span class="line"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text()</span><br><span class="line">    href = a[<span class="hljs-string">'href]</span></span><br></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161028152315.png" alt=""></p>
<p>然后我们在随便打开一个上面打印出来的链接地址，会发现页面中只有一张图啊，点击 下一页 会发现 url 一直在变，就是在第一张图的 url 后跟 ‘/‘ + 数字，就代表第几张图。所以只需拿到最后一张图的页码，然后访问第一张图到最后一张图所有的url就可以爬到全部的图了。</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2016/10/QQ%E6%88%AA%E5%9B%BE20161028164035-1024x580.png" alt=""></p>
<p>观察发现页码栏都在<code>&lt;div class=&#39;pagenavi&#39;&gt;</code> 标签下，而最后一页的页码是 标签中倒数第二个 <code>&lt;span&gt;</code> 中的内容，所以这一波操作来了</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125; <span class="hljs-comment">## 浏览器请求头</span></span><br><span class="line"></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span></span><br><span class="line"></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)<span class="hljs-comment">##使用 requests 来获取 all_url 的内容，并且把 headers 作为请求头</span></span><br><span class="line"></span><br><span class="line">all_soup = BeutifulSoup(start_html.text,<span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span></span><br><span class="line"></span><br><span class="line">all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>) <span class="hljs-comment">##意思是先查找 class 为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span></span><br><span class="line"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text()</span><br><span class="line">    href = a[<span class="hljs-string">'href]</span></span><br><span class="line"><span class="hljs-string">    html = requests.get(href,headers=headers)</span></span><br><span class="line"><span class="hljs-string">    html_soup = BeautifulSoup(html.text,'</span>lxml)</span><br><span class="line">    max_span = html_soup.find(<span class="hljs-string">'div'</span>,class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">-2</span>].get_text()<span class="hljs-comment">##[-2]代表倒数第二个</span></span><br><span class="line">    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span)+<span class="hljs-number">1</span>):</span><br><span class="line">        page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">        print(page_url)</span><br></pre></td></tr></table></figure>
<p>这时我们就得到了每张图所在的链接地址，距离爬到我们心心念念的图片地址还有最后一步。发现我们需要的地址在 <code>&lt;div class=”main-image”&gt;</code> 中的 <code>&lt;img&gt;</code> 标签的 src 属性中。</p>
<p>继续操作一波</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125; <span class="hljs-comment">## 浏览器请求头</span></span><br><span class="line"></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span></span><br><span class="line"></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)<span class="hljs-comment">##使用 requests 来获取 all_url 的内容，并且把 headers 作为请求头</span></span><br><span class="line"></span><br><span class="line">all_soup = BeutifulSoup(start_html.text,<span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span></span><br><span class="line"></span><br><span class="line">all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>) <span class="hljs-comment">##意思是先查找 class 为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span></span><br><span class="line"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text()</span><br><span class="line">    href = a[<span class="hljs-string">'href]</span></span><br><span class="line"><span class="hljs-string">    html = requests.get(href,headers=headers)</span></span><br><span class="line"><span class="hljs-string">    html_soup = BeautifulSoup(html.text,'</span>lxml)</span><br><span class="line">    max_span = html_soup.find(<span class="hljs-string">'div'</span>,class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">-2</span>].get_text()<span class="hljs-comment">##[-2]代表倒数第二个</span></span><br><span class="line">    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span)+<span class="hljs-number">1</span>):</span><br><span class="line">        page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">        page_html = requests.get(page_url,headers=headers)</span><br><span class="line">        page_soup = BeautifulSoup(page_html.text, <span class="hljs-string">'lxml'</span>)</span><br><span class="line">        img_url = page_soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">        print(img_url)</span><br></pre></td></tr></table></figure>
<p>hahahah，完美，这不就是我们想要的嘛。但是还要继续操作，我们只拿到了图片的 url ，还要把这些图片下载到本地才算“爬虫”啊。</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests <span class="hljs-comment">##导入requests</span></span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup <span class="hljs-comment">##导入bs4中的BeautifulSoup</span></span><br><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="hljs-string">'User-Agent'</span>:<span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;<span class="hljs-comment">##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）</span></span><br><span class="line">all_url = <span class="hljs-string">'http://www.mzitu.com/all'</span>  <span class="hljs-comment">##开始的URL地址</span></span><br><span class="line">start_html = requests.get(all_url,  headers=headers)  <span class="hljs-comment">##使用requests中的get方法来获取all_url(就是：http://www.mzitu.com/all这个地址)的内容 headers为上面设置的请求头、请务必参考requests官方文档解释</span></span><br><span class="line">Soup = BeautifulSoup(start_html.text, <span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##使用BeautifulSoup来解析我们获取到的网页（‘lxml’是指定的解析器 具体请参考官方文档哦）</span></span><br><span class="line">all_a = Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>) <span class="hljs-comment">##意思是先查找 class为 all 的div标签，然后查找所有的&lt;a&gt;标签。</span></span><br><span class="line"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">    title = a.get_text() <span class="hljs-comment">#取出a标签的文本</span></span><br><span class="line">    path = str(title).strip() <span class="hljs-comment">##去掉空格</span></span><br><span class="line">    os.makedirs(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path)) <span class="hljs-comment">##创建一个存放套图的文件夹</span></span><br><span class="line">    os.chdir(<span class="hljs-string">"D:\mzitu\\"</span>+path) <span class="hljs-comment">##切换到上面创建的文件夹</span></span><br><span class="line">    href = a[<span class="hljs-string">'href'</span>] <span class="hljs-comment">#取出a标签的href 属性</span></span><br><span class="line">    html = requests.get(href, headers=headers) <span class="hljs-comment">##上面说过了</span></span><br><span class="line">    html_Soup = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>) <span class="hljs-comment">##上面说过了</span></span><br><span class="line">    max_span = html_Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'pagenavi'</span>).find_all(<span class="hljs-string">'span'</span>)[<span class="hljs-number">-2</span>].get_text() <span class="hljs-comment">##查找所有的&lt;span&gt;标签获取第十个的&lt;span&gt;标签中的文本也就是最后一个页面了。</span></span><br><span class="line">    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span)+<span class="hljs-number">1</span>): <span class="hljs-comment">##不知道为什么这么用的小哥儿去看看基础教程吧</span></span><br><span class="line">        page_url = href + <span class="hljs-string">'/'</span> + str(page) <span class="hljs-comment">##同上</span></span><br><span class="line">        img_html = requests.get(page_url, headers=headers)</span><br><span class="line">        img_Soup = BeautifulSoup(img_html.text, <span class="hljs-string">'lxml'</span>)</span><br><span class="line">        img_url = img_Soup.find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>] <span class="hljs-comment">##这三行上面都说过啦不解释了哦</span></span><br><span class="line">        name = img_url[<span class="hljs-number">-9</span>:<span class="hljs-number">-4</span>] <span class="hljs-comment">##取URL 倒数第四至第九位 做图片的名字</span></span><br><span class="line">        img = requests.get(img_url, headers=headers)</span><br><span class="line">        f = open(name+<span class="hljs-string">'.jpg'</span>, <span class="hljs-string">'ab'</span>)<span class="hljs-comment">##写入多媒体文件必须要 b 这个参数！！必须要！！</span></span><br><span class="line">        f.write(img.content) <span class="hljs-comment">##多媒体文件要是用conctent哦！</span></span><br><span class="line">        f.close()</span><br></pre></td></tr></table></figure>
<p>然后进行进一步的封装</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> requests</span><br><span class="line"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="hljs-keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">mzitu</span><span class="hljs-params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">all_url</span><span class="hljs-params">(self, url)</span>:</span></span><br><span class="line">        html = self.request(url)<span class="hljs-comment">##调用request函数把套图地址传进去会返回给我们一个response</span></span><br><span class="line">        all_a = BeautifulSoup(html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'all'</span>).find_all(<span class="hljs-string">'a'</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> all_a:</span><br><span class="line">            title = a.get_text()</span><br><span class="line">            print(<span class="hljs-string">u'开始保存：'</span>, title) <span class="hljs-comment">##加点提示不然太枯燥了</span></span><br><span class="line">            path = str(title).replace(<span class="hljs-string">"?"</span>, <span class="hljs-string">'_'</span>) <span class="hljs-comment">##我注意到有个标题带有 ？  这个符号Windows系统是不能创建文件夹的所以要替换掉</span></span><br><span class="line">            self.mkdir(path) <span class="hljs-comment">##调用mkdir函数创建文件夹！这儿path代表的是标题title哦！！！！！不要糊涂了哦！</span></span><br><span class="line">            href = a[<span class="hljs-string">'href'</span>]</span><br><span class="line">            self.html(href) <span class="hljs-comment">##调用html函数把href参数传递过去！href是啥还记的吧？ 就是套图的地址哦！！不要迷糊了哦！</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">html</span><span class="hljs-params">(self, href)</span>:</span>   <span class="hljs-comment">##这个函数是处理套图地址获得图片的页面地址</span></span><br><span class="line">        html = self.request(href)</span><br><span class="line">        max_span = BeautifulSoup(html.text, 'lxml').find('div', class='pagenavi').find_all('span')[-2].get_text()</span><br><span class="line">        <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, int(max_span) + <span class="hljs-number">1</span>):</span><br><span class="line">            page_url = href + <span class="hljs-string">'/'</span> + str(page)</span><br><span class="line">            self.img(page_url) <span class="hljs-comment">##调用img函数</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img</span><span class="hljs-params">(self, page_url)</span>:</span> <span class="hljs-comment">##这个函数处理图片页面地址获得图片的实际地址</span></span><br><span class="line">        img_html = self.request(page_url)</span><br><span class="line">        img_url = BeautifulSoup(img_html.text, <span class="hljs-string">'lxml'</span>).find(<span class="hljs-string">'div'</span>, class_=<span class="hljs-string">'main-image'</span>).find(<span class="hljs-string">'img'</span>)[<span class="hljs-string">'src'</span>]</span><br><span class="line">        self.save(img_url)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span><span class="hljs-params">(self, img_url)</span>:</span> <span class="hljs-comment">##这个函数保存图片</span></span><br><span class="line">        name = img_url[<span class="hljs-number">-9</span>:<span class="hljs-number">-4</span>]</span><br><span class="line">        img = self.request(img_url)</span><br><span class="line">        f = open(name + <span class="hljs-string">'.jpg'</span>, <span class="hljs-string">'ab'</span>)</span><br><span class="line">        f.write(img.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mkdir</span><span class="hljs-params">(self, path)</span>:</span> <span class="hljs-comment">##这个函数创建文件夹</span></span><br><span class="line">        path = path.strip()</span><br><span class="line">        isExists = os.path.exists(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isExists:</span><br><span class="line">            print(<span class="hljs-string">u'建了一个名字叫做'</span>, path, <span class="hljs-string">u'的文件夹！'</span>)</span><br><span class="line">            os.makedirs(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path))</span><br><span class="line">            os.chdir(os.path.join(<span class="hljs-string">"D:\mzitu"</span>, path)) <span class="hljs-comment">##切换到目录</span></span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">True</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            print(<span class="hljs-string">u'名字叫做'</span>, path, <span class="hljs-string">u'的文件夹已经存在了！'</span>)</span><br><span class="line">            <span class="hljs-keyword">return</span> <span class="hljs-keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">request</span><span class="hljs-params">(self, url)</span>:</span> <span class="hljs-comment">##这个函数获取网页的response 然后返回</span></span><br><span class="line">        headers = &#123;<span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>&#125;</span><br><span class="line">        content = requests.get(url, headers=headers)</span><br><span class="line">        <span class="hljs-keyword">return</span> content</span><br><span class="line"></span><br><span class="line">Mzitu = mzitu() <span class="hljs-comment">##实例化</span></span><br><span class="line">Mzitu.all_url(<span class="hljs-string">'http://www.mzitu.com/all'</span>) <span class="hljs-comment">##给函数all_url传入参数  你可以当作启动爬虫（就是入口）</span></span><br></pre></td></tr></table></figure>
<p>大功告成！</p>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-06-04T14:29:06.000Z">
                    2017-06-04</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Django/">Django</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    12 分钟 读完 (大约 1861 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/06/04/Django表单/">
                Django表单</a>
            
        </h1>
        <div class="content">
            <h1 id="Http请求"><a href="#Http请求" class="headerlink" title="Http请求"></a>Http请求</h1><h2 id="GET-方法"><a href="#GET-方法" class="headerlink" title="GET 方法"></a>GET 方法</h2><p>在 HelloWorld 项目下创建 search.py:<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"><span class="hljs-keyword">from</span> django.shortcuts <span class="hljs-keyword">import</span> render_to_response</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_form</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">return</span> render_to_response(<span class="hljs-string">'search_form.html'</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    request.encoding = <span class="hljs-string">'utf-8'</span></span><br><span class="line">    <span class="hljs-keyword">if</span> <span class="hljs-string">'q'</span> <span class="hljs-keyword">in</span> request.GET:</span><br><span class="line">        message = <span class="hljs-string">'你搜索的内容为：'</span> + request.GET[<span class="hljs-string">'q'</span>]</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        message = <span class="hljs-string">'你提交了空表单'</span></span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(message)</span><br></pre></td></tr></table></figure></p>
<p>在模板目录 templates 中添加 search_form.html 表单：<br><figure class="highlight html hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">"utf-8"</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>菜鸟教程(runoob.com)<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">action</span>=<span class="hljs-string">"/search"</span> <span class="hljs-attr">method</span>=<span class="hljs-string">"get"</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">"text"</span> <span class="hljs-attr">name</span>=<span class="hljs-string">"q"</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">"submit"</span> <span class="hljs-attr">value</span>=<span class="hljs-string">"搜索"</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">form</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>并且修改 urls.py:<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.conf.urls <span class="hljs-keyword">import</span> url</span><br><span class="line"><span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> view,testdb,search</span><br><span class="line"> </span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(<span class="hljs-string">r'^hello$'</span>, view.hello),</span><br><span class="line">    url(<span class="hljs-string">r'^testdb$'</span>, testdb.testdb),</span><br><span class="line">    url(<span class="hljs-string">r'^search-form$'</span>, search.search_form),</span><br><span class="line">    url(<span class="hljs-string">r'^search$'</span>, search.search),</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>访问地址 <a href="http://127.0.0.1:8000/search-form" target="_blank" rel="noopener">http://127.0.0.1:8000/search-form</a> 并搜索，结果如下所示:<br><img src="http://www.runoob.com/wp-content/uploads/2015/01/django1.gif" alt=""></p>
<h2 id="POST-方法"><a href="#POST-方法" class="headerlink" title="POST 方法"></a>POST 方法</h2><p>在tmplate 创建 post.html：<br><figure class="highlight html hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">"utf-8"</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>POST测试<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">action</span>=<span class="hljs-string">"/search-post"</span> <span class="hljs-attr">method</span>=<span class="hljs-string">"post"</span>&gt;</span></span><br><span class="line">        &#123;% csrf_token %&#125;</span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">"text"</span> <span class="hljs-attr">name</span>=<span class="hljs-string">"q"</span>&gt;</span></span><br><span class="line">        <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">"submit"</span> <span class="hljs-attr">value</span>=<span class="hljs-string">"Submit"</span>&gt;</span></span><br><span class="line">    <span class="hljs-tag">&lt;/<span class="hljs-name">form</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">    <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>&#123;&#123; rlt &#125;&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>在模板的末尾，我们增加一个 rlt 记号，为表格处理结果预留位置。<br>表格后面还有一个{\% csrf_token \%}的标签。csrf 全称是 Cross Site Request Forgery。这是Django提供的防止伪装提交请求的功能。POST 方法提交的表格，必须有此标签。<br>在HelloWorld目录下新建 search2.py 文件并使用 search_post 函数来处理 POST 请求：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.shortcuts <span class="hljs-keyword">import</span> render</span><br><span class="line"><span class="hljs-keyword">from</span> django.views.decorators <span class="hljs-keyword">import</span> csrf</span><br><span class="line"> </span><br><span class="line"><span class="hljs-comment"># 接收POST请求数据</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_post</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    ctx =&#123;&#125;</span><br><span class="line">    <span class="hljs-keyword">if</span> request.POST:</span><br><span class="line">        ctx[<span class="hljs-string">'rlt'</span>] = request.POST[<span class="hljs-string">'q'</span>]</span><br><span class="line">    <span class="hljs-keyword">return</span> render(request, <span class="hljs-string">"post.html"</span>, ctx)</span><br></pre></td></tr></table></figure></p>
<p>修改 urls.py ：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.conf.urls <span class="hljs-keyword">import</span> url</span><br><span class="line"><span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> view,testdb,search,search2</span><br><span class="line"> </span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(<span class="hljs-string">r'^hello$'</span>, view.hello),</span><br><span class="line">    url(<span class="hljs-string">r'^testdb$'</span>, testdb.testdb),</span><br><span class="line">    url(<span class="hljs-string">r'^search-form$'</span>, search.search_form),</span><br><span class="line">    url(<span class="hljs-string">r'^search$'</span>, search.search),</span><br><span class="line">    url(<span class="hljs-string">r'^search-post$'</span>, search2.search_post),</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<h2 id="Request-对象"><a href="#Request-对象" class="headerlink" title="Request 对象"></a>Request 对象</h2><p>每个 view 函数的第一个参数是一个 HttpRequest 对象，就像下面这个 hello() 函数:<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hello</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(<span class="hljs-string">"Hello world"</span>)</span><br></pre></td></tr></table></figure></p>
<p>HttpRequest对象包含当前请求URL的一些信息：</p>
<table barder="1"><br>    <tr><br>        <th align="left">属性</th><br>        <th align="left">描述</th><br>    </tr><br>    <tr><br>        <th align="left">path</th><br>        <th align="left">请求页面的全路径,不包括域名—例如, “/hello/“</th><br>    </tr><br>    <tr><br>        <th align="left">method</th><br>        <th align="left"><br><br>请求中使用的HTTP方法的字符串表示。全大写表示。例如:<br><br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> request.method == <span class="hljs-string">'GET'</span>:</span><br><span class="line"></span><br><span class="line">    do_something()</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">elif</span> request.method == <span class="hljs-string">'POST'</span>:</span><br><span class="line"></span><br><span class="line">    do_something_else()</span><br></pre></td></tr></table></figure><br><br></th><br><br></tr><br>    <tr><br>        <th align="left">GET</th><br>        <th align="left">包含所有HTTP GET参数的类字典对象。参见QueryDict 文档</th><br>    </tr><br>    <tr><br>        <th align="left">POST</th><br>        <th align="left">包含所有HTTP POST参数的类字典对象。参见QueryDict 文档。<br>服务器收到空的POST请求的情况也是有可能发生的。也就是说，表单form通过HTTP POST方法提交请求，但是表单中可以没有数据。因此，不能使用语句if request.POST来判断是否使用HTTP POST方法；应该使用if request.method == “POST” (参见本表的method属性)。<br><br>注意: POST不包括file-upload信息。参见FILES属性。</th><br>    </tr><br>    <tr><br>        <th align="left">REQUEST</th><br>        <th align="left">为了方便，该属性是POST和GET属性的集合体，但是有特殊性，先查找POST属性，然后再查找GET属性。借鉴PHP’s $_REQUEST。<br>例如，如果GET = {“name”: “john”} 和POST = {“age”: ‘34’},则 REQUEST[“name”] 的值是”john”, REQUEST[“age”]的值是”34”.<br>强烈建议使用GET and POST,因为这两个属性更加显式化，写出的代码也更易理解。</th><br>    </tr><br>    <tr><br>        <th align="left">COOKIES</th><br>        <th align="left">包含所有cookies的标准Python字典对象。Keys和values都是字符串。</th><br>    </tr><br>    <tr><br>        <th align="left">FILES</th><br>        <th align="left">包含所有上传文件的类字典对象。FILES中的每个Key都是 <code>&lt;input type=&quot;file&quot; name=&quot;&quot; /&gt;</code>标签中name属性的值. FILES中的每个value 同时也是一个标准Python字典对象，包含下面三个Keys:<br><em> filename: 上传文件名,用Python字符串表示
</em> content-type: 上传文件的Content type<br><em> content: 上传文件的原始内容<br><br>注意：只有在请求方法是POST，并且请求页面中<form>有enctype=”multipart/form-data”属性时FILES才拥有数据。否则，FILES 是一个空字典。</form></em></th><br>    </tr><br>    <tr><br>        <th align="left">META</th><br>        <th align="left">包含所有可用HTTP头部信息的字典。 例如:
 CONTENT_LENGTH<br><em> CONTENT_TYPE
</em> QUERY_STRING: 未解析的原始查询字符串<br><em> REMOTE_ADDR: 客户端IP地址
</em> REMOTE_HOST: 客户端主机名<br><em> SERVER_NAME: 服务器主机名
</em> SERVER_PORT: 服务器端口<br><br>META 中这些头加上前缀HTTP_最为Key, 例如:<br><em> HTTP_ACCEPT_ENCODING
</em> HTTP_ACCEPT_LANGUAGE<br><em> HTTP_HOST: 客户发送的HTTP主机头信息
</em> HTTP_REFERER: referring页<br><em> HTTP_USER_AGENT: 客户端的user-agent字符串
</em> HTTP_X_BENDER: X-Bender头信息</th><br>    </tr><br>    <tr><br>        <th align="left">user</th><br>        <th align="left">是一个django.contrib.auth.models.User 对象，代表当前登录的用户。<br>如果访问用户当前没有登录，user将被初始化为django.contrib.auth.models.AnonymousUser的实例。<br>你可以通过user的is_authenticated()方法来辨别用户是否登录：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> request.user.is_authenticated():</span><br><span class="line">    <span class="hljs-comment"># Do something for logged-in users.</span></span><br><span class="line"><span class="hljs-keyword">else</span>:</span><br><span class="line">    <span class="hljs-comment"># Do something for anonymous users.</span></span><br></pre></td></tr></table></figure><br><br>只有激活Django中的AuthenticationMiddleware时该属性才可用<br></th><br>    </tr><br>    <tr><br>        <th align="left">session</th><br>        <th align="left">唯一可读写的属性，代表当前会话的字典对象。只有激活Django中的session支持时该属性才可用</th><br>    </tr><br>    <tr><br>        <th align="left">raw_post_data</th><br>        <th align="left">原始HTTP POST数据，未解析过。 高级处理时会有用处。</th><br>    </tr><br><br></table>

<p>Request对象也有一些有用的方法：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>__getitem__(key)</td>
<td>返回GET/POST的键值,先取POST,后取GET。如果键不存在抛出 KeyError。这是我们可以使用字典语法访问HttpRequest对象。例如,request[“foo”]等同于先request.POST[“foo”] 然后 request.GET[“foo”]的操作。</td>
</tr>
<tr>
<td>has_key()</td>
<td>检查request.GET or request.POST中是否包含参数指定的Key。</td>
</tr>
<tr>
<td>get_full_path()</td>
<td>返回包含查询字符串的请求路径。例如， “/music/bands/the_beatles/?print=true”</td>
</tr>
<tr>
<td>is_secure()</td>
<td>如果请求是安全的，返回True，就是说，发出的是HTTPS请求。</td>
</tr>
</tbody>
</table>
<h2 id="QueryDict对象"><a href="#QueryDict对象" class="headerlink" title="QueryDict对象"></a>QueryDict对象</h2><p>在HttpRequest对象中, GET和POST属性是django.http.QueryDict类的实例。<br>QueryDict类似字典的自定义类，用来处理单键对应多值的情况。<br>QueryDict实现所有标准的词典方法。还包括一些特有的方法：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>__getitem__</td>
<td>和标准字典的处理有一点不同，就是，如果Key对应多个Value，__getitem__()返回最后一个value。</td>
</tr>
<tr>
<td>__setitem__</td>
<td>设置参数指定key的value列表(一个Python list)。注意：它只能在一个mutable QueryDict 对象上被调用(就是通过copy()产生的一个QueryDict对象的拷贝).</td>
</tr>
<tr>
<td>get()</td>
<td>如果key对应多个value，get()返回最后一个value。</td>
</tr>
<tr>
<td>update()</td>
<td>参数可以是QueryDict，也可以是标准字典。和标准字典的update方法不同，该方法添加字典 items，而不是替换它们</td>
</tr>
<tr>
<td>items()</td>
<td>和标准字典的items()方法有一点不同,该方法使用单值逻辑的__getitem__():</td>
</tr>
<tr>
<td>values()</td>
<td>和标准字典的values()方法有一点不同,该方法使用单值逻辑的__getitem__():</td>
</tr>
</tbody>
</table>
<p>QueryDict也有一些方法，如下表：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>copy()</td>
<td>返回对象的拷贝，内部实现是用Python标准库的copy.deepcopy()。该拷贝是mutable(可更改的) — 就是说，可以更改该拷贝的值。</td>
</tr>
<tr>
<td>getlist(key)</td>
<td>返回和参数key对应的所有值，作为一个Python list返回。如果key不存在，则返回空list。 It’s guaranteed to return a list of some sort..</td>
</tr>
<tr>
<td>setlist(key,list_)</td>
<td>设置key的值为list_ (unlike __setitem__()).</td>
</tr>
<tr>
<td>appendlist(key,item)</td>
<td>添加item到和key关联的内部list.</td>
</tr>
<tr>
<td>setlistdefault(key,list)</td>
<td>和setdefault有一点不同，它接受list而不是单个value作为参数。</td>
</tr>
<tr>
<td>lists()</td>
<td>和items()有一点不同, 它会返回key的所有值，作为一个list</td>
</tr>
<tr>
<td>urlencode()</td>
<td>返回一个以查询字符串格式进行格式化后的字符串(e.g., “a=2&amp;b=3&amp;b=5”).</td>
</tr>
</tbody>
</table>

        </div>
        
        
        
    </div>
</div>





    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <!--  -->
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2017-06-04T09:52:10.000Z">
                    2017-06-04</time>
                
                <div class="level-item">
                    <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Django/">Django</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 分钟 读完 (大约 813 个字)
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
            <a class="has-link-black-ter" href="/2017/06/04/Django模型/">
                Django模型</a>
            
        </h1>
        <div class="content">
            <p>Django 对各种数据库提供了很好的支持，包括：PostgreSQL、MySQL、SQLite、Oracle。<br>Django 为这些数据库提供了统一的调用API。 我们可以根据自己业务需求选择不同的数据库。</p>
<p>可以使用 <code>pip install mysqlclient</code> 来安装 mysql 驱动</p>
<h1 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h1><p>在项目的 settings.py 文件中找到 DATABASES 配置项，将其信息修改为：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DATABASES = &#123;</span><br><span class="line">    <span class="hljs-string">'default'</span>: &#123;</span><br><span class="line">        <span class="hljs-string">'ENGINE'</span>: <span class="hljs-string">'django.db.backends.mysql'</span>,</span><br><span class="line">        <span class="hljs-string">'NAME'</span>: <span class="hljs-string">'test'</span>,</span><br><span class="line">        <span class="hljs-string">'USER'</span>: <span class="hljs-string">'root'</span>,</span><br><span class="line">        <span class="hljs-string">'PASSWORD'</span>: <span class="hljs-string">'0107'</span>,</span><br><span class="line">        <span class="hljs-string">'HOST'</span>: <span class="hljs-string">'localhost'</span>,</span><br><span class="line">        <span class="hljs-string">'PORT'</span>:<span class="hljs-string">'3306'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h1><p>Django规定，如果要使用模型，必须要创建一个app。我们使用以下命令创建一个 TestModel 的 app:<br><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py startapp TestModel</span><br></pre></td></tr></table></figure></p>
<p>目录结构如下：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HelloWorld</span><br><span class="line">|-- TestModel</span><br><span class="line">|   |-- __init__.py</span><br><span class="line">|   |-- admin.py</span><br><span class="line">|   |-- models.py</span><br><span class="line">|   |-- tests.py</span><br><span class="line">|   `-- views.py</span><br></pre></td></tr></table></figure></p>
<p>修改 TestModel/models.py 文件，代码如下：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.db <span class="hljs-keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Test</span><span class="hljs-params">(models.Model)</span>:</span></span><br><span class="line">    name = models.CharField(max_length=<span class="hljs-number">20</span>)</span><br></pre></td></tr></table></figure></p>
<p>以上的类名代表了数据库表名，且继承了 models.Model ，类里面的字段代表数据表中的字段(name)，数据类型则由 CharField（相当于varchar）、DateField（相当于datetime）， max_length 参数限定长度。<br>接下来在 settings.py 中找到 INSTALLED_APPS 这一项，如下：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">    <span class="hljs-string">'django.contrib.admin'</span>,</span><br><span class="line">    <span class="hljs-string">'django.contrib.auth'</span>,</span><br><span class="line">    <span class="hljs-string">'django.contrib.contenttypes'</span>,</span><br><span class="line">    <span class="hljs-string">'django.contrib.sessions'</span>,</span><br><span class="line">    <span class="hljs-string">'django.contrib.messages'</span>,</span><br><span class="line">    <span class="hljs-string">'django.contrib.staticfiles'</span>,</span><br><span class="line">    <span class="hljs-string">'TestModel'</span>,               <span class="hljs-comment"># 添加此项</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>在命令行中运行<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python manage.py migrate   # 创建表结构</span><br><span class="line"></span><br><span class="line">python manage.py makemigrations TestModel  # 让 Django 知道我们在我们的模型有一些变更</span><br><span class="line"></span><br><span class="line">python manage.py migrate TestModel   # 创建表结构</span><br></pre></td></tr></table></figure></p>
<p>然后在 HelloWorld 目录下添加 testdb.py，代码如下：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"><span class="hljs-keyword">from</span> TestModel.models <span class="hljs-keyword">import</span> Test</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">testdb</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    test1 = Test(name=<span class="hljs-string">'runoob'</span>)</span><br><span class="line">    test1.save()</span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(<span class="hljs-string">"&lt;p&gt;数据添加成功！&lt;/p&gt;"</span>)</span><br></pre></td></tr></table></figure></p>
<p>并且修改 urls.py<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.conf.urls <span class="hljs-keyword">import</span> *</span><br><span class="line"><span class="hljs-keyword">from</span> . <span class="hljs-keyword">import</span> view,testdb</span><br><span class="line"></span><br><span class="line">urlpatterns=[</span><br><span class="line">    url(<span class="hljs-string">r'^hello'</span>, view.hello),</span><br><span class="line">    url(<span class="hljs-string">r'^testdb'</span>, testdb.testdb),</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<p>访问 <code>http://127.0.0.1:8000/testdb</code> 就可以看到数据添加成功的提示。</p>
<h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"> </span><br><span class="line"><span class="hljs-keyword">from</span> TestModel.models <span class="hljs-keyword">import</span> Test</span><br><span class="line"> </span><br><span class="line"><span class="hljs-comment"># 数据库操作</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">testdb</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    <span class="hljs-comment"># 初始化</span></span><br><span class="line">    response = <span class="hljs-string">""</span></span><br><span class="line">    response1 = <span class="hljs-string">""</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 通过objects这个模型管理器的all()获得所有数据行，相当于SQL中的SELECT * FROM</span></span><br><span class="line">    list = Test.objects.all()</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-comment"># filter相当于SQL中的WHERE，可设置条件过滤结果</span></span><br><span class="line">    response2 = Test.objects.filter(id=<span class="hljs-number">1</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 获取单个对象</span></span><br><span class="line">    response3 = Test.objects.get(id=<span class="hljs-number">1</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 限制返回的数据 相当于 SQL 中的 OFFSET 0 LIMIT 2;</span></span><br><span class="line">    Test.objects.order_by(<span class="hljs-string">'name'</span>)[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment">#数据排序</span></span><br><span class="line">    Test.objects.order_by(<span class="hljs-string">"id"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 上面的方法可以连锁使用</span></span><br><span class="line">    Test.objects.filter(name=<span class="hljs-string">"runoob"</span>).order_by(<span class="hljs-string">"id"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 输出所有数据</span></span><br><span class="line">    <span class="hljs-keyword">for</span> var <span class="hljs-keyword">in</span> list:</span><br><span class="line">        response1 += var.name + <span class="hljs-string">" "</span></span><br><span class="line">    response = response1</span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(<span class="hljs-string">"&lt;p&gt;"</span> + response + <span class="hljs-string">"&lt;/p&gt;"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="更新数据"><a href="#更新数据" class="headerlink" title="更新数据"></a>更新数据</h2><p>修改数据可以用 save() 或者 update():<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"> </span><br><span class="line"><span class="hljs-keyword">from</span> TestModel.models <span class="hljs-keyword">import</span> Test</span><br><span class="line"> </span><br><span class="line"><span class="hljs-comment"># 数据库操作</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">testdb</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    <span class="hljs-comment"># 修改其中一个id=1的name字段，再save，相当于SQL中的UPDATE</span></span><br><span class="line">    test1 = Test.objects.get(id=<span class="hljs-number">1</span>)</span><br><span class="line">    test1.name = <span class="hljs-string">'Google'</span></span><br><span class="line">    test1.save()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 另外一种方式</span></span><br><span class="line">    <span class="hljs-comment">#Test.objects.filter(id=1).update(name='Google')</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 修改所有的列</span></span><br><span class="line">    <span class="hljs-comment"># Test.objects.all().update(name='Google')</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(<span class="hljs-string">"&lt;p&gt;修改成功&lt;/p&gt;"</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h2><p>删除数据库中的对象只需调用该对象的delete()方法即可：<br><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> django.http <span class="hljs-keyword">import</span> HttpResponse</span><br><span class="line"> </span><br><span class="line"><span class="hljs-keyword">from</span> TestModel.models <span class="hljs-keyword">import</span> Test</span><br><span class="line"> </span><br><span class="line"><span class="hljs-comment"># 数据库操作</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">testdb</span><span class="hljs-params">(request)</span>:</span></span><br><span class="line">    <span class="hljs-comment"># 删除id=1的数据</span></span><br><span class="line">    test1 = Test.objects.get(id=<span class="hljs-number">1</span>)</span><br><span class="line">    test1.delete()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 另外一种方式</span></span><br><span class="line">    <span class="hljs-comment"># Test.objects.filter(id=1).delete()</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 删除所有数据</span></span><br><span class="line">    <span class="hljs-comment"># Test.objects.all().delete()</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">return</span> HttpResponse(<span class="hljs-string">"&lt;p&gt;删除成功&lt;/p&gt;"</span>)</span><br></pre></td></tr></table></figure></p>

        </div>
        
        
        
    </div>
</div>






    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous is-invisible is-hidden-mobile">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/page/0/">上一页</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/page/2/">下一页</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link is-current" href="/tags/Python/">1</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/page/2/">2</a></li>
            
        </ul>
    </nav>
</div>
</div>
                


<div class="column has-order-1 is-4-tablet is-4-desktop is-3-widescreen ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered">
                <div>
                    <img class="image is-128x128 has-mb-6" src="/images/ha.jpg">
                    
                    <p class="is-size-4 is-block">
                        changoal
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        十年之前和现在
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="material-icons is-size-5 has-mr-7">location_on</i>
                        <span>BeiJing</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered">
                <div>
                    <p class="heading">
                        文章
                    </p>
                    <p class="title has-text-weight-normal">
                        74
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered">
                <div>
                    <p class="heading">
                        分类
                    </p>
                    <p class="title has-text-weight-normal">
                        16
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered">
                <div>
                    <p class="heading">
                        标签
                    </p>
                    <p class="title has-text-weight-normal">
                        30
                    </p>
                </div>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="http://github.com/changoal">
                关注我</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white" target="_blank"
                title="Github" href="http://github.com/changoal">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white" target="_blank"
                title="Twitter" href="http://twitter.com/Changoall">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white" target="_blank"
                title="Weibo" href="https://weibo.com/p/1005056712011575">
                
                <i class="fab fa-weibo"></i>
                
            </a>
            
            <a class="level-item button is-white" target="_blank"
                title="Zhihu" href="http://www.zhihu.com/people/changoal">
                
                <i class="fab fa-zhihu"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        

<div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            链接
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level" href="http://blog.kinderriven.cn/" target="_blank">
                    <span class="level-left">
                        <span class="level-item">花月阁</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://blog.kinderriven.cn/</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level" href="http://blog.csdn.net/LEE18254290736" target="_blank">
                    <span class="level-left">
                        <span class="level-item">LEE</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://blog.csdn.net/LEE18254290736</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level" href="http://gongchen.net.cn/" target="_blank">
                    <span class="level-left">
                        <span class="level-item">宫晨写字的地方</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://gongchen.net.cn/</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level" href="http://blog.alrise.xyz/" target="_blank">
                    <span class="level-left">
                        <span class="level-item">求学</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://blog.alrise.xyz/</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level" href="http://leoshi.me/" target="_blank">
                    <span class="level-left">
                        <span class="level-item">Leo Shi</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://leoshi.me/</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level" href="http://2naive.cn/" target="_blank">
                    <span class="level-left">
                        <span class="level-item">大队长</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">http://2naive.cn/</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>


    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                分类
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/Android/">
            <span class="level-start">
                <span class="level-item">Android</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">20</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Java/">
            <span class="level-start">
                <span class="level-item">Java</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Python/">
            <span class="level-start">
                <span class="level-item">Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">10</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Python/Django/">
            <span class="level-start">
                <span class="level-item">Django</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Python/爬虫/">
            <span class="level-start">
                <span class="level-item">爬虫</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">7</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/师太/">
            <span class="level-start">
                <span class="level-item">师太</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/想说的/">
            <span class="level-start">
                <span class="level-item">想说的</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/摄影/">
            <span class="level-start">
                <span class="level-item">摄影</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/数据结构/">
            <span class="level-start">
                <span class="level-item">数据结构</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/文字/">
            <span class="level-start">
                <span class="level-item">文字</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/文字/收藏/">
            <span class="level-start">
                <span class="level-item">收藏</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/生活/">
            <span class="level-start">
                <span class="level-item">生活</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/算法/">
            <span class="level-start">
                <span class="level-item">算法</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/编程思想/">
            <span class="level-start">
                <span class="level-item">编程思想</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/足球/">
            <span class="level-start">
                <span class="level-item">足球</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            标签云
        </h3>
        <a href="/tags/Android/" style="font-size: 20px;">Android</a> <a href="/tags/Android开发艺术探索/" style="font-size: 11.43px;">Android开发艺术探索</a> <a href="/tags/Dagger/" style="font-size: 11.43px;">Dagger</a> <a href="/tags/Django/" style="font-size: 14.29px;">Django</a> <a href="/tags/Java/" style="font-size: 11.43px;">Java</a> <a href="/tags/Lottie/" style="font-size: 10px;">Lottie</a> <a href="/tags/Python/" style="font-size: 18.57px;">Python</a> <a href="/tags/RecyclerView/" style="font-size: 10px;">RecyclerView</a> <a href="/tags/RxJava/" style="font-size: 10px;">RxJava</a> <a href="/tags/Scrapy/" style="font-size: 11.43px;">Scrapy</a> <a href="/tags/bug/" style="font-size: 10px;">bug</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/动态权限申请/" style="font-size: 10px;">动态权限申请</a> <a href="/tags/北漂/" style="font-size: 11.43px;">北漂</a> <a href="/tags/师太/" style="font-size: 12.86px;">师太</a> <a href="/tags/想说的/" style="font-size: 17.14px;">想说的</a> <a href="/tags/感悟/" style="font-size: 10px;">感悟</a> <a href="/tags/排序/" style="font-size: 10px;">排序</a> <a href="/tags/推荐/" style="font-size: 10px;">推荐</a> <a href="/tags/摄影/" style="font-size: 10px;">摄影</a> <a href="/tags/收藏/" style="font-size: 10px;">收藏</a> <a href="/tags/数据结构/" style="font-size: 11.43px;">数据结构</a> <a href="/tags/文字/" style="font-size: 10px;">文字</a> <a href="/tags/杂/" style="font-size: 12.86px;">杂</a> <a href="/tags/爬虫/" style="font-size: 15.71px;">爬虫</a> <a href="/tags/生活/" style="font-size: 12.86px;">生活</a> <a href="/tags/编程思想/" style="font-size: 10px;">编程思想</a> <a href="/tags/足球/" style="font-size: 12.86px;">足球</a> <a href="/tags/随笔/" style="font-size: 11.43px;">随笔</a> <a href="/tags/面试/" style="font-size: 10px;">面试</a>
    </div>
</div>

    
    
        <div class="card card-transparent is-hidden-widescreen">
        
            
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2019/03/06/Dependency-Injection-with-Dagger-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Dependency Injection with Dagger 2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-03-06T08:39:37.000Z">2019-03-06</time></div>
                    <a href="/2019/03/06/Dependency-Injection-with-Dagger-2/" class="has-link-black-ter is-size-6">Dependency Injection with Dagger 2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/03/06/Dagger2-使用/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Dagger2 使用">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-03-06T08:39:24.000Z">2019-03-06</time></div>
                    <a href="/2019/03/06/Dagger2-使用/" class="has-link-black-ter is-size-6">Dagger2 使用</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/31/2018-end/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="2018 end">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-31T12:59:51.000Z">2018-12-31</time></div>
                    <a href="/2018/12/31/2018-end/" class="has-link-black-ter is-size-6">2018 end</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/生活/">生活</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/26/Android-屏幕适配/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/thumbnails/landscape.jpg" alt="Android 屏幕适配">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-26T11:27:44.000Z">2018-12-26</time></div>
                    <a href="/2018/12/26/Android-屏幕适配/" class="has-link-black-ter is-size-6">Android 屏幕适配</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/06/RxJava系列-一-入门/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/thumbnails/landscape.jpg" alt="RxJava系列(一) 入门">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-06T14:46:22.000Z">2018-12-06</time></div>
                    <a href="/2018/12/06/RxJava系列-一-入门/" class="has-link-black-ter is-size-6">RxJava系列(一) 入门</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                标签
            </h3>
            <ul class="menu-list">
                
                <li>
                    <a class="level is-marginless" href="/tags/Android/">
                        <span class="level-start">
                            <span class="level-item">Android</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">29</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Android开发艺术探索/">
                        <span class="level-start">
                            <span class="level-item">Android开发艺术探索</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Dagger/">
                        <span class="level-start">
                            <span class="level-item">Dagger</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Django/">
                        <span class="level-start">
                            <span class="level-item">Django</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">4</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Java/">
                        <span class="level-start">
                            <span class="level-item">Java</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Lottie/">
                        <span class="level-start">
                            <span class="level-item">Lottie</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Python/">
                        <span class="level-start">
                            <span class="level-item">Python</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">12</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/RecyclerView/">
                        <span class="level-start">
                            <span class="level-item">RecyclerView</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/RxJava/">
                        <span class="level-start">
                            <span class="level-item">RxJava</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Scrapy/">
                        <span class="level-start">
                            <span class="level-item">Scrapy</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/bug/">
                        <span class="level-start">
                            <span class="level-item">bug</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/linux/">
                        <span class="level-start">
                            <span class="level-item">linux</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/动态权限申请/">
                        <span class="level-start">
                            <span class="level-item">动态权限申请</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/北漂/">
                        <span class="level-start">
                            <span class="level-item">北漂</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/师太/">
                        <span class="level-start">
                            <span class="level-item">师太</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/想说的/">
                        <span class="level-start">
                            <span class="level-item">想说的</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">8</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/感悟/">
                        <span class="level-start">
                            <span class="level-item">感悟</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/排序/">
                        <span class="level-start">
                            <span class="level-item">排序</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/推荐/">
                        <span class="level-start">
                            <span class="level-item">推荐</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/摄影/">
                        <span class="level-start">
                            <span class="level-item">摄影</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/收藏/">
                        <span class="level-start">
                            <span class="level-item">收藏</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/数据结构/">
                        <span class="level-start">
                            <span class="level-item">数据结构</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/文字/">
                        <span class="level-start">
                            <span class="level-item">文字</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/杂/">
                        <span class="level-start">
                            <span class="level-item">杂</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/爬虫/">
                        <span class="level-start">
                            <span class="level-item">爬虫</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">7</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/生活/">
                        <span class="level-start">
                            <span class="level-item">生活</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/编程思想/">
                        <span class="level-start">
                            <span class="level-item">编程思想</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/足球/">
                        <span class="level-start">
                            <span class="level-item">足球</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/随笔/">
                        <span class="level-start">
                            <span class="level-item">随笔</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/面试/">
                        <span class="level-start">
                            <span class="level-item">面试</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                


<div class="column has-order-3 is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only">
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            最新文章
        </h3>
        
        <article class="media">
            
            <a href="/2019/03/06/Dependency-Injection-with-Dagger-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Dependency Injection with Dagger 2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-03-06T08:39:37.000Z">2019-03-06</time></div>
                    <a href="/2019/03/06/Dependency-Injection-with-Dagger-2/" class="has-link-black-ter is-size-6">Dependency Injection with Dagger 2</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/03/06/Dagger2-使用/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Dagger2 使用">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-03-06T08:39:24.000Z">2019-03-06</time></div>
                    <a href="/2019/03/06/Dagger2-使用/" class="has-link-black-ter is-size-6">Dagger2 使用</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/31/2018-end/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="2018 end">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-31T12:59:51.000Z">2018-12-31</time></div>
                    <a href="/2018/12/31/2018-end/" class="has-link-black-ter is-size-6">2018 end</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/生活/">生活</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/26/Android-屏幕适配/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/thumbnails/landscape.jpg" alt="Android 屏幕适配">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-26T11:27:44.000Z">2018-12-26</time></div>
                    <a href="/2018/12/26/Android-屏幕适配/" class="has-link-black-ter is-size-6">Android 屏幕适配</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2018/12/06/RxJava系列-一-入门/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/gallery/thumbnails/landscape.jpg" alt="RxJava系列(一) 入门">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2018-12-06T14:46:22.000Z">2018-12-06</time></div>
                    <a href="/2018/12/06/RxJava系列-一-入门/" class="has-link-black-ter is-size-6">RxJava系列(一) 入门</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Android/">Android</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                标签
            </h3>
            <ul class="menu-list">
                
                <li>
                    <a class="level is-marginless" href="/tags/Android/">
                        <span class="level-start">
                            <span class="level-item">Android</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">29</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Android开发艺术探索/">
                        <span class="level-start">
                            <span class="level-item">Android开发艺术探索</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Dagger/">
                        <span class="level-start">
                            <span class="level-item">Dagger</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Django/">
                        <span class="level-start">
                            <span class="level-item">Django</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">4</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Java/">
                        <span class="level-start">
                            <span class="level-item">Java</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Lottie/">
                        <span class="level-start">
                            <span class="level-item">Lottie</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Python/">
                        <span class="level-start">
                            <span class="level-item">Python</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">12</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/RecyclerView/">
                        <span class="level-start">
                            <span class="level-item">RecyclerView</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/RxJava/">
                        <span class="level-start">
                            <span class="level-item">RxJava</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/Scrapy/">
                        <span class="level-start">
                            <span class="level-item">Scrapy</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/bug/">
                        <span class="level-start">
                            <span class="level-item">bug</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/linux/">
                        <span class="level-start">
                            <span class="level-item">linux</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/动态权限申请/">
                        <span class="level-start">
                            <span class="level-item">动态权限申请</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/北漂/">
                        <span class="level-start">
                            <span class="level-item">北漂</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/师太/">
                        <span class="level-start">
                            <span class="level-item">师太</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/想说的/">
                        <span class="level-start">
                            <span class="level-item">想说的</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">8</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/感悟/">
                        <span class="level-start">
                            <span class="level-item">感悟</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/排序/">
                        <span class="level-start">
                            <span class="level-item">排序</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/推荐/">
                        <span class="level-start">
                            <span class="level-item">推荐</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/摄影/">
                        <span class="level-start">
                            <span class="level-item">摄影</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/收藏/">
                        <span class="level-start">
                            <span class="level-item">收藏</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/数据结构/">
                        <span class="level-start">
                            <span class="level-item">数据结构</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/文字/">
                        <span class="level-start">
                            <span class="level-item">文字</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/杂/">
                        <span class="level-start">
                            <span class="level-item">杂</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/爬虫/">
                        <span class="level-start">
                            <span class="level-item">爬虫</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">7</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/生活/">
                        <span class="level-start">
                            <span class="level-item">生活</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/编程思想/">
                        <span class="level-start">
                            <span class="level-item">编程思想</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/足球/">
                        <span class="level-start">
                            <span class="level-item">足球</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">3</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/随笔/">
                        <span class="level-start">
                            <span class="level-item">随笔</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">2</span>
                        </span>
                    </a>
                </li>
                
                <li>
                    <a class="level is-marginless" href="/tags/面试/">
                        <span class="level-start">
                            <span class="level-item">面试</span>
                        </span>
                        <span class="level-end">
                            <span class="level-item tag">1</span>
                        </span>
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/icon_round.png" alt="" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 chang&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        href="http://github.com/ppoffice/hexo-theme-icarus">Icarus</a>
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="http://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>
    <script>
        (function ($) {
            $(document).ready(function () {
                if (typeof($.fn.lightGallery) === 'function') {
                    $('.article').lightGallery({ selector: '.gallery-item' });
                }
                if (typeof($.fn.justifiedGallery) === 'function') {
                    $('.justified-gallery').justifiedGallery();
                }
            });
        })(jQuery);
    </script>
    

    
    
    
    <div id="outdated">
        <h6>Your browser is out-of-date!</h6>
        <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p>
        <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js"></script>
    <script>
        $(document).ready(function () {
            // plugin function, place inside DOM ready function
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'flex'
            })
        });
    </script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/animejs@2.2.0/anime.js"></script>
    <script>
    function isIE() {
        var ua = window.navigator.userAgent;
        var msie = ua.indexOf('MSIE ');
        var trident = ua.indexOf('Trident/');
        return (msie > 0 || trident > 0);
    }

    $(document).ready(function () {
        $('body').css('opacity', 1);
        if (!isIE()) {
            ['.main > .column:first-child .card',
            '.main > .column:nth-child(2) .card',
            '.main > .column:last-child .card'].map(function(target) {
                anime({
                    targets: target,
                    scale: [0.8, 1],
                    opacity: [0, 1],
                    duration: 300,
                    easing: 'easeOutSine',
                    delay: function(el, i, l) {
                        return i * 100;
                    }
                })
            });
    
            anime({
                targets: '.navbar-main',
                translateY: [-100, 0],
                opacity: [0, 1],
                duration: 300,
                easing: 'easeOutSine'
            });
        }
    });
    </script>
    

    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {matchFontHeight: false},
        SVG: {matchFontHeight: false},
        CommonHTML: {matchFontHeight: false}
    });
</script>

    
    

<div id="back-to-top" class="is-flex is-flex-center is-hidden-tablet">
    <i class="material-icons">keyboard_arrow_up</i>
    <span class="is-size-7">
        回到顶端</span>
</div>
<script>
    $(document).ready(function () {
        var lastScrollTop = 0;
        $(window).scroll(function (event) {
            var scrollTop = $(this).scrollTop();
            if (scrollTop > lastScrollTop || scrollTop === 0) {
                $('#back-to-top').removeClass('is-active');
            } else {
                $('#back-to-top').addClass('is-active');
            }
            lastScrollTop = scrollTop;
        });
        $('#back-to-top').on('click', function () {
            $('body, html').animate({ scrollTop: 0 }, 400);
        });
    });
</script>


    
    

    
    
    
    

    


<script src="/js/main.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="想要查找什么..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>